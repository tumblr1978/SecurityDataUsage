Language-based Defenses against  

Untrusted Browser Origins

Karthikeyan Bhargavan and Antoine Delignat-Lavaud, INRIA Paris-Rocquencourt;  

Sergio Maffeis, Imperial College London

Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14â€“16, 2013 â€¢ Washington, D.C., USAISBN 978-1-931971-03-4Language-based Defenses against Untrusted Browser Origins

Karthikeyan Bhargavan

INRIA Paris-Rocquencourt

Antoine Delignat-Lavaud
INRIA Paris-Rocquencourt

Sergio Maffeis

Imperial College London

Abstract

We present new attacks and robust countermeasures for
security-sensitive components, such as single sign-on
APIs and client-side cryptographic libraries, that need to
be safely deployed on untrusted web pages. We show
how failing to isolate such components leaves them vul-
nerable to attacks both from the hosting website and
other components running on the same page. These
attacks are not prevented by browser security mecha-
nisms alone, because they are caused by code interact-
ing within the same origin. To mitigate these attacks,
we propose to combine ï¬ne-grained component isola-
tion at the JavaScript level with cryptographic mecha-
nisms. We present Defensive JavaScript (DJS), a subset
of the language that guarantees the behavior integrity of
scripts even when loaded in a hostile environment. We
give a sound type system, type inference tool, and build
defensive libraries for cryptography and data encodings.
We show the effectiveness of our solution by implement-
ing several applications using defensive patterns that ï¬x
some of our original attacks. We present a model extrac-
tion tool to analyze the security properties of our appli-
cations using a cryptographic protocol veriï¬er.

1 Defensive Web Components

Web users increasingly store sensitive data on servers
spread across the web. The main advantage of this dis-
persal is that users can access their data from browsers on
multiple devices, and easily share this data with friends
and colleagues. The main drawback is that concentrat-
ing sensitive data on servers makes them tempting targets
for cyber-criminals, who use increasingly sophisticated
browser-based attacks to steal user data.

In response to these concerns, web applications now
offer users more control over who gets access to their
data, using authorization protocols such as OAuth [23]
and application-level cryptography.
These security
mechanisms are often implemented as JavaScript com-
ponents that may be included by any website, where they
mediate a three-party interaction between the host web-
site, the user (represented by her browser), and a server
that holds the sensitive data on behalf of the user.

Website	 Â (W)	 Â 

Data	 Â Server	 Â (S)	 Â 

Db	 Â 

uâ€™s Browser 

Web Page (HTML) 

Security	 Â 

Component	 Â 
(JavaScript)	 Â 

API 

Cookies 

Local  
Storage 

Figure 1: JavaScript Security Component

The typical deployment scenario that concerns us is
depicted in Figure 1. A website W wishes to access sen-
sitive user data stored at S. So, it embeds a JavaScript
component provided by S. When a user visits the web-
site, the component authenticates the user and exposes
an API through which W may access the userâ€™s data, if
the user has previously authorized W at S. For authenti-
cated users on authorized websites, the component typ-
ically holds some client-side secret, such as an access
token or encryption key, which it can use to validate data
requests and responses. When the user closes or navi-
gates away from the website, the component disappears
and the website can no longer access the API.

A popular example of this scenario is single sign-on
mechanism, such as Login with Facebook (detailed in
Section 2). Facebook (S) provides a JavaScript compo-
nent that websites like Pinterest (W ) may use to request
the identity and social proï¬le of a visiting user, via an
API that obtains a secret OAuth token for the current user
and attaches it with each request to Facebook.

Other examples include payment processing APIs like
Google Checkout, password manager bookmarklets like
Lastpass, anti-CSRF protections like OWASP CSRF-
Guard, and client-side encryption libraries for cloud stor-
age services like Mega. More generally, a website may
host a number of components from different providers,
each keeping its own secrets and protecting its own API.
What we ï¬nd particularly interesting is that the data
and functionality of these JavaScript components is of-
ten of higher value that the website that hosts it. This is
contrary to the usual web security threat model where

USENIX Association  

22nd USENIX Security Symposium  653

1

a website tries to defend itself from third-party com-
ponents. Instead, we consider components that are de-
signed to increase security of a website by delegating
sensitive operations (e.g. password storage, credit card
approval) to trusted third-party servers. For the data han-
dled by such components, we seek to offer a limited se-
curity guarantee to the user. If a user temporarily vis-
its (and authorizes) a compromised website W , any data
read by the website during the visit may be leaked to the
adversary, but the user can still expect the component to
protect long-term access to her data on S. Our aim is
not to prevent compromises in W or to prevent all data
leaks. Instead, we enable a robust defense-in-depth strat-
egy, where the security mechanisms of a website do not
completely break if it loads a single malicious script.
Goals, Threats, and Attacks. Our goal is to design
hardened JavaScript components that can protect sensi-
tive user data and other long-term secrets such as access
tokens and encryption keys from unauthorized parties.
So far, such goals have proven surprisingly hard to guar-
antee for components written in JavaScript that run in
the browser environment and interact with standard web-
sites (e.g. see [1, 5, 6, 10, 41, 42]). What makes such
components so hard to secure?

In Section 2, we survey the state of the art in three
categories of security components: single sign-on mech-
anisms, password managers, and client-side encryption
libraries used for cloud storage. We ï¬nd that these com-
ponents must defend against three kinds of threats. First,
they may be loaded into a malicious website that pretends
to be a trusted website. Second, even on a trusted web-
site they may be loaded alongside other scripts that may
innocently (or maliciously) modify the JavaScript builtin
objects in a way that changes the runtime behavior of the
component. Third, some webpage on the same domain
(or subdomain) as W may either host malicious user-
provided content or might contain a cross-site scripting
(XSS) attack or any number of web vulnerabilities.

We found that the defenses against these threats prove
inadequate for many of the components in our survey.
We report previously-unknown attacks on widely-used
components that completely compromise their stated se-
curity goals, despite their use of sophisticated protocols
and cryptographic mechanisms. Our attacks exploit a
wide range of problems, such as bugs in JavaScript com-
ponents, bugs in browsers, and standard web vulnerabili-
ties (XSS, CSRF, open redirectors), and build upon them
to fool components into revealing their secrets. Eliminat-
ing speciï¬c bugs and vulnerabilities can only be a stop-
gap measure. We aim instead to design JavaScript com-
ponents that are provably robust against untrusted hosts.
Same Origin Policy (SOP). Most browser security
mechanisms (including new HTML5 APIs, such as







Browser 

Web Page (HTML) 

age

API 















Cookies 

Local  
Storage 

DJS checker 

no 

defensive? 

yes 

	





secu
?
secure? 
yes 

no 
nono 

ProVerif 

Figure 2: DJS Architecture

postMessage, localStorage, and WebCrypto) are based
on the origin from which a webpage was loaded, deï¬ned
as the domain of the website and the protocol and port
used to retrieve it (e.g. https://facebook.com:443). The
SOP isolates the JavaScript execution environments of
frames and windows loaded from different origins from
each other.
In contrast, frames from the same origin
can directly access each otherâ€™s variables and functions,
across a page and even across windows.

The SOP does not directly apply to our scenario since
our components run in the same origin as the host web-
site. To use the SOP, components must open new frames
or windows on a separate origin and implement a mes-
saging protocol between them and the host website. As
we show in Section 2, such components are difï¬cult to
get right and the JavaScript programs that implement
them require close analysis.
Our Proposal. We advocate a language-based approach
that is complementary to the SOP and protects scripts
running in the same origin from each other. This enables
a defense-in-depth strategy where the functionality and
secrets of a component can be protected even if some
page on the host origin is compromised.

We propose a defensive architecture (Figure 2) that en-
ables developers to write veriï¬ed JavaScript components
that combine cryptography and browser security mecha-
nisms to provide strong formal guarantees against entire
classes of attacks. Its main elements are:

DJS: A defensive subset of JavaScript, with a static type

checker, for writing security-critical components.

DJS Library: A library written (and typechecked) in

DJS, with cryptographic and encoding functions.

DJS2PV: A tool that automatically analyzes the compo-
sitional security of a DJS component by translating
it to the applied pi calculus for veriï¬cation when
combined with models of the browser and DJS li-
brary, using the ProVerif protocol analyzer.

Script Server: A veriï¬ed server for distributing defen-
sive scripts embedded with session-speciï¬c encryp-
tion keys.

654  22nd USENIX Security Symposium 

USENIX Association

2

Our architecture relies on the willingness of devel-
opers to program security-critical code in DJS, a well-
deï¬ned restricted subset of JavaScript.
In return, they
obtain automated analysis and strong security guarantees
for their code. Moreover, no restriction is enforced on
untrusted code. In order to verify authentication and se-
crecy properties of the defensive components once em-
bedded in the browser, we rely on ProVerif [13], a stan-
dard protocol veriï¬cation tool that has been used exten-
sively to analyze cryptographic mechanisms, with the
WebSpi library [6], a recent model for web security
mechanisms. Unlike previous works that use WebSpi,
we automatically extract models from DJS code.

As we show in Section 6, DJS can signiï¬cantly im-
prove the security of current web applications with min-
imal changes to their functionality. Emerging web se-
curity solutions, such as Content Security Policy, EC-
MAScript 5 Strict, and WebCryptoAPI, offer comple-
mentary protections, and when they become widespread,
they may enable us to relax some DJS restrictions, while
retaining its strong security guarantees.
Towards Defensive JavaScript. A cornerstone of our
defensive architecture is the ability of trusted scripts
to resist same-origin attacks, because requiring that all
scripts on an origin be trusted is too demanding. We
investigate language-based isolation for such trusted
scripts, and identify the defensive JavaScript problem:
Deï¬ne a defensive subset of JavaScript to write state-
ful functions whose behavior cannot be inï¬‚uenced (be-
sides by their arguments) by untrusted code running in
the same environment, before or after such functions are
deï¬ned. Untrusted code should not be able to learn se-
crets by accessing the source code of defensive functions
or directly accessing their internal state.

This problem is harder than the one tackled by
JavaScript subsets such as ADsafe [16] or Caja [40],
which aim to protect trusted scripts by sandboxing un-
trusted components. In particular, those subsets assume
the initial JavaScript environment is trusted, and that all
untrusted code can be restricted. In our case, defensive
code must run securely in a JavaScript engine that is run-
ning arbitrary untrusted code.
Contributions. Our main contributions are:

1. We identify common concerns for applications that
embed secure components in arbitrary third party
websites, and new attacks on these applications;

2. We present DJS, a defensive subset of JavaScript for
programming security components. DJS is the ï¬rst
language-based isolation mechanism that does not
restrict untrusted JavaScript and does not rely on a
ï¬rst-running bootstrapper;

3. We develop tools to verify that JavaScript code is
valid DJS, and to extract ProVerif models from DJS;

4. We deï¬ne DJCL, a defensive crypto library with en-
coding and decoding utilities that can be safely used
in untrusted JavaScript environments. DJCL can be
included as is on any website;

5. We identify general patterns that leverage DJS and
cryptography to enforce component isolation in the
browser, and in particular, we propose ï¬xes to sev-
eral broken web applications.

Supporting materials for this paper, including code,
demos, and a technical report with proofs are available
online [11].

2 Attacks on Web Security Components

We survey a series of web security components and in-
vestigate their security; Table 1 presents our results. Our
survey focuses on three categories of security compo-
nents that implement the pattern depicted in Figure 1.
Single Sign-On Buttons:(e.g. Facebook login on Hulu)
W loads a script from S that allows it to access the
veriï¬ed identity of u at S, and possibly other social
data (photo, friend list, etc.).

Password Managers: (e.g. LastPass, 1Password)

u installs a browser plugin or bookmarklet from S;
when the browser visits W , the plugin retrieves an
(encrypted) password or credit card number for u
from S and uses it to ï¬ll in a form on W .

Host-Proof Cloud Storage: (e.g. Conï¬Chair, Mega)

A privacy-sensitive website W loads a client-side
encryption library from S that retrieves an encrypted
ï¬le from the cloud, decrypts it with a user-speciï¬ed
key (or passphrase) and releases the ï¬le to W .

We conjecture that other security components that ï¬t our
threat model, such as payment processing APIs and so-
cial sharing widgets, would have similar security goals
and solutions, and suffer from similar weaknesses.
Methodology. Our method for studying each compo-
nent is as follows. We ï¬rst study the source code of
each component and run it in various environments to
discover the core protection mechanisms that it depends
on. For example, in order to protect the integrity of their
JavaScript code from the hosting webpage, some com-
ponents require users to install them as bookmarklets
(e.g. LastPass) or browser extensions (e.g. 1Password),
whereas others rely on their code being downloaded
within frames (e.g. Facebook), within signed Java ap-
plets (e.g. Wuala) or as signed JavaScript (e.g. Mega). In
order to protect the conï¬dentiality of data, many compo-
nents rely on cryptography, implemented either in Java
or in JavaScript. We anticipate that many of these will
eventually use the native HTML Web Cryptography API
when it becomes widely available.

USENIX Association  

22nd USENIX Security Symposium  655

3

Product
Facebook

Category
Single Sign-On Provider

Protection Mechanism Attack Vectors Found
Frames

Helios, Yahoo, Bitly
WordPress, Dropbox
Firefox

Single Sign-On Clients

OAuth Login

Web Browser

Same-Origin Policy

1Password, RoboForm

Password Manager

Browser Extension

LastPass, PassPack
Verisign, SuperGenPass
SpiderOak

Password Manager

Encrypted Cloud Storage

Bookmarklet, Frames,
JavaScript Crypto
Server-side Crypto

Origin Spooï¬ng,
URL Parsing Confusion
HTTP Redirector,
Hosted Pages
Malicious JavaScript,
CSP Reports
URL Parsing Confusion,
Metadata Tampering
Malicious JavaScript
URL Parsing Confusion
CSRF

Wuala

Encrypted Cloud Storage

Java Applet, Crypto

Client-side Exposure

Mega
Conï¬Chair, Helios

Encrypted Cloud Storage
Crypto Web Applications

JavaScript Crypto
Java Applet, Crypto

XSS
XSS

Table 1: Survey: Representative Attacks on Security Components

Secrets Stolen
Login Credential,
API Access Token
Login Credential,
API Access Token
Login Credential,
API Access Token
Password

Bookmarklet Secret,
Encryption Key
Files,
Encryption Key
Files,
Encryption Key
Encryption Key
Password,
Encryption Key

Next, we investigate whether any of these protection
mechanisms make assumptions about the browser, or the
security of the host website, or component server, that
could be easily broken. We found a variety of bugs
in speciï¬c JavaScript components and in the Firefox
browser, and we found standard web vulnerabilities in
various websites (CSRF, XSS, Open Redirectors).

Finally, the bulk of the analysis consists in converting
these bugs and vulnerabilities to concrete exploits on our
target JavaScript components. Table 1 only reports the
exploits that resulted in a complete circumvention of the
componentâ€™s security, that is, attacks where long-term se-
crets like encryption keys and user ï¬les are leaked. We
also found other, arguably less serious, attacks not noted
here, such as CSRF and login CSRF attacks on the data
server and attacks that enable user tracking and ï¬nger-
printing.

In this section, we detail two illustrative examples of

our analysis. For details on our other attacks, see [11].

2.1 Login with Facebook

Hosting Webpage (W) 

0. login() 

Facebook	 Â JavaScript	 Â SDK	 Â 

 token 

Facebook	 Â 

API	 Â 

1. cookie, W 

2. token 

Facebook	 Â OAuth	 Â 

IFrame	 Â 

/oauth/?origin=W	 Â 

login	 Â 

3. token 

4. token 

Facebook	 Â Proxy	 Â 

IFrame	 Â 

/proxy?parent=W	 Â 

When a website W wants to incorporate single-sign on
with Facebook (S) on one of its pages, it can simply in-
clude the Facebook JavaScript SDK and call FB.login().
Behind the scene, this kicks off a three-party authoriza-

tion protocol called OAuth 2.0 [23], where an authoriza-
tion server on Facebook issues an access token to W if
the currently logged-in user has authorized W for single
sign-on; otherwise, the user is asked to log in and autho-
rize W . W may then call FB.getAccessToken to obtain the
raw token, but more commonly, it calls FB.api to make
speciï¬c calls to Facebookâ€™s REST API (with the token
attached). Hence, W can read the current userâ€™s veri-
ï¬ed identity at Facebook or other social data. Google,
Live, and Twitter provide a similar experience with their
JavaScript SDKs.

When W calls FB.login, two iframes are created.

The ï¬rst OAuth iframe is sourced from Facebookâ€™s au-
thorization server with W â€™s client id (IW ) as parameter:
https://www.facebook.com/dialog/oauth?client id=IW
This page authenticates the user (with a cookie), veriï¬es
that she has authorized W, issues a fresh access token (T)
and redirects the iframe to a Facebook URL with the to-
ken as fragment identiï¬er:
https://static.ak.facebook.com/connect/xd arbiter.php#token=T

Meanwhile, the second Proxy iframe is loaded from:

https://static.ak.facebook.com/connect/xd arbiter.php#origin=W
where the fragment identiï¬er indicates the origin W of
the host page. Since both frames are now on the same
origin, they can directly read each otherâ€™s variables and
call each otherâ€™s functions. The OAuth iframe calls a
function on the Proxy iframe with the access token T, and
this function forwards T in a postMessage event to the par-
ent frame (with target origin set to W ). The token is then
received by a waiting FB.login callback function, and to-
ken retrieval is complete. W can call FB.api to verify the
userâ€™s identity and access token.

656  22nd USENIX Security Symposium 

USENIX Association

4

Protection Mechanisms. The main threat to the above
exchange is from a malicious website M pretending to be
W . The Facebook JavaScript SDK relies on the following
browser security mechanisms:

â€¢ Both iframes are sourced from origins distinct from
M, so scripts on M cannot interfere with these
frames, except to set their source URIs;

the page; M cannot read the redirection URI;

â€¢ The redirection of the OAuth frame is transparent to
â€¢ Scripts on M cannot directly access Facebook be-
cause the browser and the web server will prevent
such cross-origin accesses;

event, since it is set to target origin W .

â€¢ Scripts on M will not be able to read the postMessage
All four mechanisms are variations of the SOP (ap-
plied to iframes, redirection URIs, XmlHttpRequest, and
postMessage). The intuition is that if M and W are dif-
ferent origins, their actions (even on the same page) are
opaque to each other. However, many aspects of the SOP
are not standard but browser-speciï¬c and open to inter-
pretation [43]. For example, we show bugs in recent ver-
sions of Firefox that break redirection transparency.

Writing JavaScript code to compose browser mecha-
nisms securely is not easy. We demonstrate several bugs
in the Facebook SDK that enable M to bypass origin au-
thentication. Moreover, the SOP does not distinguish be-
tween same-origin pages or scripts. Hence, a hidden as-
sumption in the above exchange is that all scripts loaded
on all pages of W have access to the token and must be
trusted. We show how sub-origin attacks on Facebookâ€™s
client can steal tokens.
Breaking Redirection Transparency on Firefox. We
found two bugs in how Firefox enforced the same origin
policy for redirection URIs.

First, we found that recent versions of the Firefox
browser failed to isolate frame locations. If a script opens
an iframe and stores a pointer to its document.location ob-
ject, then it continues to have access to this object even if
the URL of the frame changes, because of a user action
or a server redirection.

A second bug was in Firefoxâ€™s implementation of Con-
tent Security Policy (CSP) [38], a new mechanism to re-
strict loading of external contents to a authorized URIs.
In its CSP, a website can ask for a report on all policy
violations. If M sets its CSP to block all access to W , a
frame on M gets redirected to W , M would be notiï¬ed of
this violation by the browser. A bug in Firefox caused
the violation report to include the full URL (including
fragment identiï¬er) of the redirection, despite W and M
being different origins.

By themselves, these bugs do not seem very seri-
ous; they only allow adversaries to read URIs, not even
page contents, on frames that the adversary himself has

created. However, when combined with protocols like
OAuth that use HTTP redirection to transmit secret to-
kens in URIs, these bugs become quite serious. For ex-
ample, a malicious website M can steal a userâ€™s Facebook
token by creating an OAuth iframe with W â€™s client id and
reading the token in the redirected Facebook URI.

We reported these bugs and they are now ï¬xed, but
they highlight the difï¬culty of implementing a consistent
policy across an increasing number of browser features.
Breaking Origin Authentication in FB.login.
Al-
though the OAuth iframe only obtains access tokens for
an authorized origin W and the Proxy iframe only re-
leases access tokens to the origin in its fragment identi-
ï¬er, there is no check guaranteeing that these origins are
the same. Suppose a malicious website M opened the
OAuth iframe with W â€™s client id, but a Proxy iframe with
Mâ€™s origin. The OAuth iframe duly gets the token for W
and passes it to the Proxy iframe that forwards the token
to M. Hence, M has stolen the userâ€™s access token for an
arbitrary W .

We reported this bug and Facebook quickly addressed
the attack by adding code for origin agreement between
the two frames. However, we found two other ways to
bypass this origin comparison by exploiting bugs in the
componentâ€™s URL parsing functions.
Sub-origin Attacks on Facebook Clients. The design
of the Facebook login component protects against cross-
origin attackers (e.g. an unauthorized host website) but
not provide any protections against untrusted content and
ordinary web vulnerabilities on authorized host websites.
We found that Wordpress and Dropbox both allow
users to host HTML pages on subdomains; we were able
to exploit this feature to write user content that obtained
access tokens meant for the main website. We also found
an open redirector on the electronic voting site Helios
that allowed any malicious website to steal a userâ€™s ac-
cess token for Helios; the website could then vote in the
userâ€™s name. This was a bug, but similar redirectors ap-
pear by design on Yahoo search and Bitly, leading to to-
ken theft, as shown in previous work [6].

These attacks were reported and are now prevented by
either moving user content to a different domain or by
ensuring that Facebook only releases tokens to a distinct
subdomain (e.g. open.login.yahoo.com). However, pages
on the main website still need to be given the token so
that they can access the Facebook proï¬le of the user.
We found that websites like Wordpress and Hulu leave
their Facebook access tokens embedded in their web-
pages, where they may be read by any number of other
scripts, including competing social plugins from Twitter,
framework libraries like jQuery, and advertising and an-
alytics libraries from Google and others. At their most
benign, these scripts could read the access token to track

USENIX Association  

22nd USENIX Security Symposium  657

5

Facebook users; if they were malicious, they could im-
personate the user and read her Yahooo mail or exï¬ltrate
her full social proï¬le for advertising use.

2.2 Client-side Decryption for Cloud Data
Web applications often use cryptography to protect sen-
sitive user data that may be stored on untrusted servers
or may pass through untrusted browsers. A typical ex-
ample is a cloud-based ï¬le storage service, where both
users and server owners would prefer the cloud server
not to be able to read or modify any user ï¬le. To be host-
proof in this way, all user ï¬les are stored encrypted in the
cloud, using keys that are known only to the user or her
browser, but not to the storage service. All plaintext data
accesses are performed in the browser, after downloading
and decrypting ciphertext from the cloud. This architec-
ture has also been adopted by password managers and
other privacy conscious applications such as electronic
voting, encrypted chats, and conference management.

There are many challenges in getting browser-based
cryptographic solutions right, but the two main design
questions are how to trust the cryptographic library and
protect its execution, and how to store encryption keys
securely. Our survey found a variety of choices:
Browser Extensions. Password managers are often im-
plemented as browser extensions so that they can read
and write into login forms on webpages while being iso-
lated from the page. Communication between the web-
site and the page uses a browser-speciï¬c messaging API.
We found attacks on the 1Password and RoboForm ex-
tensions where a malicious website could use this API
to steal user passwords for trusted websites by exploiting
buggy URL parsing and the lack of metadata integrity in
the encrypted password database format.
Bookmarklets. Some password managers offer login
bookmarklets that contain JavaScript code with an em-
bedded encryption key that users can download and store
in their browsers. When the bookmarklet is clicked on
the login page of a website, its code is injected into the
page; it retrieves encrypted login data from the password
manager website, decrypts it, and ï¬lls in the login form.
Even if the bookmarklet is accidentally clicked on a ma-
licious page that tampers with the JavaScript builtin ob-
jects and pretends to be a different website, the book-
marklet is meant to at most reveal the userâ€™s password for
the current site. Indeed, several bookmarklets modiï¬ed
their designs to guarantee this security goal in response
to previously found attacks [1]. However, we found sev-
eral new attacks on a number of these ï¬xed bookmarklets
that still enabled malicious websites to steal passwords,
the bookmarklet encryption key, and even the userâ€™s mas-
ter encryption key.

Website JavaScript. Cloud storage services and crypto-
graphic web applications use JavaScript in the webpage
to decrypt and display ï¬les downloaded from the cloud.
Some of them (e.g. Conï¬Chair ) use Java applets to im-
plement cryptography whereas others (e.g. Mega) rely
on reputed JavaScript libraries such as SJCL [37]. How-
ever, storing encryption keys securely during an ongo-
ing session remains an open challenge. Conï¬Chair stores
keys in HTML5 localStorage; SpiderOak stores keys for
shared folders on the server, and Wuala stores encryption
keys in a hidden user ï¬le on the client. We found a CSRF
attack on SpiderOak, a client-side bug on Wuala, and an
XSS attack on Conï¬Chair, all three of which allowed
malicious websites to steal a userâ€™s encryption keys if
the user visited the website when logged into the corre-
sponding web application.

2.3 Summary
All the attacks described in this survey were responsi-
bly disclosed; most were found ï¬rst by us and ï¬xed on
our suggestion; a few were reported by us in previous
work [5, 6, 10]; some were reported and ï¬xed indepen-
dently. Our survey is not exhaustive, and many of the at-
tack vectors we employed are quite well-known. While
ï¬nding exploits on individual components took time and
expertise, the ease with which we were able to ï¬nd web
vulnerabilities on which we built these exploits was sur-
prising.
In many cases, these vulnerabilities were not
considered serious until we showed that they enabled un-
intended interactions with speciï¬c security components.
On the evidence of our survey, eliminating all un-
trusted contents and other web vulnerabilities from host-
ing websites seems infeasible.
Instead, security com-
ponents should seek to defend themselves against both
malicious websites and same-origin attackers on trusted
websites. Moreover, security checks in JavaScript com-
ponents are hard to get right, and a number of our attacks
relied on bugs in that part of the application logic. This
motivates a more formal and systematic approach to the
analysis of security-sensitive components.

3 DJS: Defensive JavaScript

In this section we deï¬ne DJS, a subset of JavaScript that
enforces a strict defensive programming style using lan-
guage restrictions and static typing. DJS makes it possi-
ble to write JavaScript security components that preserve
their behavior and protect their secrets even when loaded
into an untrusted page after other scripts have tampered
with the execution environment.

We advocate using DJS only for security-critical code;
other code in the component or on the page may remain
in full JavaScript. Hence, our approach is more suited to

658  22nd USENIX Security Symposium 

USENIX Association

6

our target applications than previous proposals that seek
to restrict untrusted code (e.g. [16, 26, 39, 40] or require
trusted code to run ï¬rst (e.g. [2]).

The rest of the section informally describes the DJS
subset and its security properties; full formal deï¬nitions
can be found in the technical report [11].

3.1 Defensiveness
The goal of defensiveness is to protect the behavioral
integrity of sensitive JavaScript functions that will be
invoked in an environment where arbitrary adversarial
code has already run. How do we model the capabili-
ties of an adversary who may be able to exploit browser
and server features that fall outside JavaScript, such as
frames, browser extensions, REST APIs, etc?

We propose a powerful attacker model inspired by
the successful Dolev-Yao attacker [18] for cryptographic
protocols, where the network is the attacker.
In
JavaScript, we claim that the memory is the attacker. We
allow the attacker to arbitrarily change one (well-formed)
JavaScript memory into another,
thus capturing even
non-standard or undocumented features of JavaScript.

Without further assumptions, this attacker is too pow-
erful to state any property of trusted programs. Hence,
like in the Dolev-Yao case where the attacker is as-
sumed unable to break encryption, we make the reason-
able assumptions that the attacker cannot forge pointers
to memory locations it doesnâ€™t have access to, and that it
cannot break into the scope frames of functions. This as-
sumption holds in principle for all known JavaScript im-
plementations, but in practice it may fail to hold because
of use-after-free bugs or prototype hijacking attacks [22].
Let a heap be a map from memory locations to
language values,
including locations themselves (like
pointers). We often reason about equivalent heaps up
to renaming of locations and garbage collection (re-
moval of locations unreachable from the native ob-
jects). Let an attacker memory be any well-formed re-
gion of the JavaScript heap containing at least all na-
tive objects required by the semantics, and without any
dangling pointer. Let a user memory be any region
of the JavaScript heap that only contains user-deï¬ned
JavaScript objects. A user memory may contain pointers
to the attacker memory. Let attacker code and user code
be function objects stored respectively in the attacker and
user memories.

Assumption 1 (Memory safety).
In any reasonable
JavaScript semantics, starting from a memory that can
be partitioned in two regions, where one is an attacker
memory and the other a user memory, the execution of
attacker code does not alter the user memory.

User code cannot run in user memory alone because it

lacks native objects and default prototypes necessary for
JavaScript executions. For that reason, we consider user
code that exposes an API in the form of a function that
may be called by the attacker. Let a function wrapper
be an arbitrary JavaScript expression E parametric in a
function deï¬nition F, which returns a wrapped function
GF. GF is meant to safely wrap F, acting as a proxy to
call F. For example:

var F = function(x) {

1 E = (function() {
2
3
4
5
6 })();

var secret = 42, key = 0xC0C0ACAFE;
return x===key ? secret : 0 }

return function G_F(x) {return

F(x>>>0) }

We now informally deï¬ne the two properties that cap-

ture defensiveness of function wrappers:
Deï¬nition 1 (Encapsulation). A function wrapper E en-
capsulates F over domain D if no JavaScript program
that runs E can distinguish between running E with F
and running E with an arbitrary function F(cid:31) without call-
ing the wrapped function GF. Moreover, for any tuple
of values Ëœv âˆˆ D, the heap resulting from calling GF( Ëœv) is
equivalent to the heap resulting from calling F( Ëœv).

In other words, encapsulation states that an attacker
with access to GF should not learn anything more about
F than is revealed by calling F on values from D. For
example, if the above E encapsulates the oracle F (lines
2-4) on numbers, an attacker may not learn secret un-
less it is returned by F, even by trying to tamper with
properties of GF such as arguments, callee...

The next property describes the integrity of the the

input-output behavior of defensive functions:
Deï¬nition 2 (Independence). A function wrapper E pre-
serves the independence of F if any two sequences of
calls to GF, interleaved with arbitrary JavaScript code,
return the same sequence of values whenever corre-
sponding calls to GF received the same parameters and
no call to GF triggered an exception.

This property is different from functional purity [19]:
since F may be stateful, it is not enough to enforce single
calls to GF to return the same value as arbitrary call se-
quences must yield matching results. Note that GF is not
prevented by this deï¬nition form causing side-effects on
its execution environment. For example, E given above
can still satisfy independence even though it will cause
a side effect when GF is passed as argument the object
{valueOf:function(){window.leak=42;return 123}}.

The above F (lines 2-4) returns its secret only when
passed the right key, and does not cause observable side-
effects. If E encapsulates F over numbers and preserves
its independence, then an attacker may not learn this se-
cret without knowing the key.

7

USENIX Association  

22nd USENIX Security Symposium  659

(cid:31)djs-program(cid:30) ::= â€˜(function(){â€™

â€˜ var _ = â€™ (cid:31)function(cid:30) â€˜;â€™
â€˜ return function(x){â€™
â€˜ if(typeof x == "string") return _(x);â€™
â€˜}})();â€™

|

|
|
|
|
|

|
|
|
|
|
|

(cid:31)function(cid:30) ::=

â€˜function(â€™ (@identiï¬er â€˜,â€™)*â€˜){â€™
(â€˜varâ€™ (@identiï¬er (â€˜=â€™ (cid:31)expression(cid:30))? â€˜,â€™)+)?
((cid:31)statement(cid:30) â€˜;â€™)*
(â€˜returnâ€™ (cid:31)expression(cid:30))? â€˜}â€™

(cid:31)statement(cid:30) ::= Îµ

â€˜with(â€™ (cid:31)lhs expression(cid:30) â€˜)â€™ (cid:31)statement(cid:30)
â€˜if(â€™ (cid:31)expression(cid:30) â€˜)â€™ (cid:31)statement(cid:30)
(â€˜elseâ€™ (cid:31)statement(cid:30))?
â€˜while(â€™ (cid:31)expression(cid:30) â€˜)â€™ (cid:31)statement(cid:30)
â€˜{â€™ ((cid:31)statement(cid:30) â€˜;â€™)* â€˜}â€™
(cid:31)expression(cid:30)

(cid:31)expression(cid:30) ::= (cid:31)literal(cid:30)

(cid:31)lhs expression(cid:30) â€˜(â€™ ((cid:31)expression(cid:30) â€˜,â€™)* â€˜)â€™
(cid:31)expression(cid:30) (cid:31)binop(cid:30) (cid:31)expression(cid:30)
(cid:31)unop(cid:30) (cid:31)expression(cid:30)
(cid:31)lhs expression(cid:30) â€˜=â€™ (cid:31)expression(cid:30)
(cid:31)dyn accessor(cid:30)
(cid:31)lhs expression(cid:30)

(cid:31)lhs expression(cid:30) ::=

| @identiï¬er | â€˜this.â€™ @identiï¬er
(cid:31)lhs expression(cid:30) â€˜[â€™ @numberâ€˜]â€™
|
(cid:31)lhs expression(cid:30) â€˜.â€™ @identiï¬er
|

(cid:31)dyn accessor(cid:30) ::=

((cid:31)x(cid:30) = @identiï¬er) â€˜[(â€™ (cid:31)expression(cid:30)
â€˜>>> 0) %â€™ (cid:31)x(cid:30) â€˜.length ]â€™
â€˜(â€™ ((cid:31)y(cid:30) = @identiï¬er) â€˜>>>=0)<â€™ ((cid:31)x(cid:30) = @identiï¬er)
â€˜.length ? x[y] : â€™ @string

|
|
| @identiï¬er â€˜[â€™ (cid:31)expression(cid:30) â€˜&â€™ (n=@number) â€˜]â€™

n âˆˆ(cid:31)1,230 âˆ’ 1(cid:30)

(cid:31)literal(cid:30) ::= (cid:31)function(cid:30)

â€˜{â€™ ( @identiï¬er â€˜:â€™ (cid:31)expression(cid:30) â€˜,â€™)* â€˜}â€™
â€˜[â€™ ((cid:31)expression(cid:30) â€˜,â€™)* â€˜]â€™

|
|
| @number | @string | @boolean

(cid:31)binop(cid:30) ::= â€˜+â€™ | â€˜-â€™ | â€˜*â€™ | â€˜/â€™ | â€˜%â€™

|
|

â€˜&â€™ | â€˜|â€™ | â€˜^â€™ | â€˜>>â€™ | â€˜<<â€™ | â€˜>>>â€™
â€˜&&â€™ | â€˜||â€™ | â€˜==â€™ | â€˜!=â€™ | â€˜>â€™ | â€˜<â€™ | â€˜>=â€™ | â€˜<=â€™

(cid:31)unop(cid:30) ::= â€˜+â€™ | â€˜-â€™ | â€˜!â€™ | â€˜~â€™

Figure 3: DJS Syntax.

Since in practice an attacker can set up the heap in such
a way that calling GF will raise an exception (e.g. stack
overï¬‚ow) regardless of the parameters passed to GF, in-
dependence only considers sequences of calls to GF that
do not trigger exceptions in GF. When an exception oc-
curs in GF, the attacker may gain access to a stack trace.
Even though stack traces only reveal function names and
line numbers in current browsers, we prevent this infor-
mation leak by always executing E within a try block.

3.2 DJS Language
In practice, JavaScript code is considered valid DJS if it
is accepted by the automatic conformance checker de-
scribed in Section 4.1, which in turn is based on the type
system of Section 3.3. The type system effectively im-
poses a restricted grammar on DJS that is given in Fig-
ure 3.
In this section, we describe the language more
informally.

Besides defensiveness, the main design goals for DJS
are: automated conformance checking (by typing), com-
patibility with currently deployed browsers (supporting
ECMAScript 3 and 5), and minimal performance over-
head. A side effect of our type system is to impose hy-
gienic coding practices similar to those of the popular
JSLint tool, encouraging high quality code that is easy to
reason about and extract veriï¬able models from.
Programs. A DJS program is a function wrapper (in the
sense of Deï¬nitions 1 and 2); its public API consists of a
single stub function from string to string that is a proxy
to a function (stored in a variable â€œ â€) in its closure. We
denote this wrapper by EDJS:

var _ = <function>;
return function(x){

1 (function(){
2
3
4
5 })();

if(typeof x == "string") return _(x)}

For simplicity, functions must begin with all their local
variables declarations, and end with a return statement:

1 function (<id>,...,<id>){
2
3
4

var <id> = <expr>,...,<id> = <expr>;
<statements>
return <expr>}

Our type system further restricts DJS statements and ex-
pressions as described below.
Preventing External References. DJS programs may
not access variables or call functions that they do not
deï¬ne themselves. For example, they may not access
DOM variables like document.location, call global func-
tions like encodeURIComponent, or access prototype func-
tions of native objects like String.indexOf.

This restriction follows directly from our threat sce-
nario, where every object not in the defensive program is
in attacker memory and may have been tampered with.
So, at the very least, values returned by external refer-
ences must be considered tainted and not used in defen-
sive computations to preserve independence. More wor-
ryingly, in JavaScript, an untrusted function that is called
by defensive code can use the caller chain starting from
its own arguments object to traverse the call stack and ob-
tain direct pointers to defensive objects (inner functions,
their arguments objects, etc.), hence breaking encapsula-
tion. Some countermeasures have been proposed to pro-

660  22nd USENIX Security Symposium 

USENIX Association

8

tect against this kind of stack-walking, but they rely on
non-standard browser features and are not very reliable
(e.g. we discovered a ï¬‚aw against the countermeasure
in [21]: trying to set the caller property of a function
to null fails, an issue immediately ï¬xed by the authors
in their online version). Future versions of JavaScript
may prohibit stack-walking, but in current browsers our
restriction is the prudent choice.

To enforce this restriction, the type system requires
all variables used in a DJS program to be lexically
scoped, within a function or scope object. For example,
var s = {x:42}; with (s){x = 4;} is valid DJS code, but
x = 4 is not.
Preventing Implicit Function Calls.
In JavaScript,
non-local access can arise for example from its non-
standard scoping rules, from the prototype-based inher-
itance mechanism, from automated type conversion and
from triggering getters and setters on object properties.
Hence, to prevent defensive code from accidentally
calling malicious external functions, DJS requires all ex-
pressions to be statically typed. This means that vari-
ables can only be assigned values of a single type; arrays
have a ï¬xed non-extensible number of (same-typed) val-
ues; objects have a non-extensible set of (typed) proper-
ties. Typing ensures that values are only accessed at the
right type and that objects and arrays are never accessed
beyond their boundaries (preventing accidental accesses
to prototypes and getters/setters). To prevent automatic
type conversion, overloaded operators (e.g. +) must only
be used with arguments of the same type.

Due to these restrictions, there is no general computed
property access e[e] in the syntax. Instead, we include a
variety of dynamic accessors to enable numeric, within-
bound property access to arrays and strings using built-in
dynamic checks, such as x[(e>>>0)%x.length].

DJS also forbids property enumeration for(i in o),

constructors and prototype inheritance.
Preventing Source Code Leakage. The source code
of a DJS program is considered secret, and should not
be available to untrusted code. We identify four attack
vectors that a trusted script can use to read (at least part
of) the source code of another script in the same origin:
using the toSource property of a function, using the stack
property of an exception, reading the code of an inline
script from the DOM, or re-loading a remote script as
data using AJAX or Flash.

To avoid the ï¬rst attack, DJS programs only export
stub functions that internally call the functions whose
source code is sensitive. Calling toSource on the former
only shows the stub code and does not reveal the source
code of the latter. As discussed at the end of Section 3.1,
we can avoid the second attack by running wrapped DJS
code within a try block. To avoid the third and fourth

Types and Environments.
(cid:31)Ï„(cid:30) ::= number | boolean | string | undeï¬ned

ËœÏ„ â†’ Ï„
ËœÏ„[Ï] â†’ Ï„
Î´

|
|
|

Base types
Function
Method operating on properties Ï
Objects and arrays

(cid:31)Î´(cid:30) ::= Ïƒ | Ïƒâˆ—
(cid:31)Ïƒ(cid:30) ::= Ï | [Ï„]n,n âˆˆ N
(cid:31)Ï(cid:30) ::= {x1 : Ï„1, . . . ,x n : Ï„n}
(cid:31)Îº(cid:30) ::= s | o
(cid:31)Î¦(cid:30) ::= Îµ | Î¦,x:Ï„
(cid:31)Î“(cid:30) ::= Îµ | Î“,[Î¦]Îº
[Ïƒâˆ— and Ïƒ are same thing sometimes]
Subtyping.

Extensible or Fixed types
Array of length n
Object with ï¬elds x1 Â·Â·Â·x n
Scope kind
Scope frame
Typing environment

Ï„ <: Ï„

Ïƒ <: Ï„
Ïƒâˆ— <: Ï„

m â‰¤ n

[Ï„]n <: [Ï„]m

J âŠ† I

{xi : Ï„i}iâˆˆI <:{x j : Ï„ j} jâˆˆJ
Ï2 <: Ï1
ËœÂµ1 â†’ Î½1 <: ËœÂµ2 â†’ Î½2
ËœÂµ1[Ï1] â†’ Î½1 <: ËœÂµ2[Ï2] â†’ Î½2

Î½1 <: Î½2
ËœÂµ2 <: ËœÂµ1
ËœÂµ1 â†’ Î½1 <: ËœÂµ2 â†’ Î½2
Figure 4: DJS types, subtyping and environments.

attacks, we advise that a defensive script should never be
directly inlined in a page; it may either be injected and
executed by a bookmarklet or browser extension, or else
it should be sourced from a dedicated secure origin that
does not allow cross-domain resource sharing.
From Coding Discipline to Static Analysis. DJS im-
poses a number of seemingly harsh restrictions on secu-
rity component developers, but most of these are moti-
vated by the hostile environments in which these com-
ponents must execute, and the strict coding discipline
pays dividends in static analysis. In Sections 5 and 6, we
show that despite these restrictions, it is still possible to
code large security components in DJS that enjoy strong
defensiveness guarantees and can be automatically ana-
lyzed for security.

3.3 Type System
DJS types and their subtyping relation are deï¬ned in Fig-
ure 4. In addition to the JavaScript base types, it includes
functions, methods, arrays and objects. Method types re-
quire a type Ï for the this parameter. Arrays are indexed
by a lower bound n on their size.

The type system of DJS is static, that is, new variables
must be initialized with a value of some type, and once
a type is assigned to a variable it cannot subsequently
change. A standard width-subtyping relation <: cap-
tures polymorphism in the length of arrays and the set
of properties of objects. However, ï¬xed types Ïƒâˆ— do not
have subtypes to guarantee soundness [14, 15, 33]. For
example, our type systems does not admit a type for the
term (function(x,y){x[0]=y; return true;})([[1]],[]).
Typing environments Î“ reï¬‚ect the nesting of the lexi-
cal scoping up to the expression that is being typed. Each

USENIX Association  

22nd USENIX Security Symposium  661

9

Obj

Î“ (cid:31) ei : Ï„i

i âˆˆ [1..n]

Î“ (cid:31) {x1 : e1, . . . ,x n : en} : {xi : Ï„i}âˆ—iâˆˆ[1..n]
Î“ (cid:31) ei : Ï„
i âˆˆ [1..n]
Î“ (cid:31) [e1, . . . ,e n] : [Ï„]âˆ—n

StrD

Î“ (cid:31) x : string

Arr

PropA

Î“ (cid:31) e : Î´

Î´ <:{x : Ï„}

Î“ (cid:31) e.x : Ï„

ArrA

Î“ (cid:31) e : Î´

Î´ <:[Ï„]n+1

Î“ (cid:31) e[n] : Ï„

Î“ (cid:31) ((y â‰«= 0) < x.length?x[y] : @string) : string

Î“ (cid:31) y : number

ArrD

Î“ (cid:31) x : [Ï„]n

Î“ (cid:31) e : number

Î“ (cid:31) x[(e â‰« 0)%x.length] : Ï„

n > 0

Scope

Assign

Î¦(x) =Ï„
Î“,[Î¦]Îº (cid:31) x : Ï„
Î“ (cid:31) e1 : Ï„

Î“,[ Ëœx : ËœÎ±,(yi : Âµi)i< j]s (cid:31) e j : Âµ j

j âˆˆ [1..m]

Î“,[ Ëœx : ËœÎ±, Ëœy : ËœÂµ]s (cid:31) s : undeï¬ned Î“,[ Ëœx : ËœÎ±, Ëœy : ËœÂµ]s (cid:31) r : Ï„

Î“ (cid:31) function ( Ëœx){var y1 = e1, . . . ,y m = em;s;return r} : ËœÎ± â†’ Ï„
Î“ (cid:31) function (this, Ëœx){s} : (Ï, ËœÎ±) â†’ Ï„

MetDef

Î“ (cid:31) function ( Ëœx){s} : ËœÎ±[Ï] â†’ Ï„
Âµ <:{x : ËœÎ±[Ï] â†’ Ï„}

Î“ (cid:31) e : Âµ

Î“ (cid:31) Ëœe : ËœÎ±

Î“ (cid:31) e.x( Ëœe) : Ï„

RecScope

x (cid:26)âˆˆ dom(Î¦)

Î“ (cid:31) x : Ï„

FunDef

Î“,[Î¦]s (cid:31) x : Ï„
Î“ (cid:31) e : { Ëœx : ËœÏ„}

Î“ (cid:31) e2 : Ï„

With

Î“ (cid:31) e1 = e2 : Ï„
FunCall

Î“ (cid:31) e : Âµ Î“ (cid:31) Ëœe : ËœÎ±

Î“ (cid:31) e( Ëœe) : Ï„

Î“,[ Ëœx : ËœÏ„]o (cid:31) s : undeï¬ned

Î“ (cid:31) with(e)s : undeï¬ned
MetCall

Âµ <: ËœÎ± â†’ Ï„

Figure 5: Selected typing rules.

scope frame Î¦ contains bindings of identiï¬ers to types,
and is annotated with s or o depending on whether the
corresponding scope object is an activation record cre-
ated by calling a function, or a user object loaded onto
the scope using with. This distinction is important to stat-
ically prevent access to prototype chains: unlike activa-
tion records, user objects cause a missing identiï¬er to be
searched in the (untrusted) object prototype rather than
in the next scope frame; thus, scope resolution must stop
at the ï¬rst frame of kind o.

Typing Rules. Most of our typing rules are standard;
here we only discuss a few representative examples, re-
ported in Figure 5; the other typing rules are detailed
in the full version [11]. For soundness, Rule Assign
does not allow subtyping. Rule Obj keeps the object
structure intact and only abstracts each ei into its cor-
responding type Ï„i. The rule for accessors and dynamic
accessors ensure that the property being accessed is di-
rectly present in the corresponding string, array or ob-
ject. For example, to typecheck Î“ (cid:31) s[3] : number using
rule ArrA, s must be typeable as an array of at least 4
numbers. The rules for dynamic accessors beneï¬t from
knowing that the index is a number modulo the size of
admissible index values. Rule RecScope looks up vari-
ables recursively only through activation records, as ex-
plained above. Rule With illustrates the case when an
object frame is added to the typing environment. The
FunDef typing rule is helped by the structure we impose
on the function body. It adds an activation record frame
to the typing environment and adds all the local variable
declarations inductively. Finally, it typechecks the body
statement s and the type of the return expression r. Rule
MetDef invokes rule FunDev after adding a formal this
parameter to the function and extending the input type
with the this type Ï. Rule FunCall is standard, whereas
rule MetCall forces an explicit syntax for method invoca-
tion in order to determine the type Ï and binding of this.

In particular, Ï must be such that method l has a function
type compatible with the potentially more general type of
its parent object l.
Formal Guarantees. The DJS type system enjoys both
type soundness (types are preserved by computation) and
progress (typed programs terminate with a ï¬nal value
and do not raise exceptions). A consequence of type
soundness is that well-typed programs are defensive. All
formal deï¬nitions and proofs leading to Theorem 1 can
be found in the technical report [11].

Theorem 1 (Defensiveness). If /0 (cid:31) F: string â†’ string
then the DJS wrapper EDJS encapsulates F over strings
and preserves its independence.

Another consequence of type soundness is that the ex-
ecution of well-typed programs does not affect attacker
memory [11]. As a consequence, execution of DJS pro-
grams is invisible to the attacker.
Extensions. We do not claim that DJS is the maximal
defensive subset of JavaScript: with a more expressive
type system, it would for instance be possible to sup-
port one level of prototype inheritence (i.e. constructors
having a literal object as prototype), or avoid certain dy-
namic accessors. Because we expect that DJS compo-
nents will mostly consist of basic control ï¬‚ow and calls
to our libraries, we do not think more expressive defen-
sive subsets of JavaScript are necessary for our goals.

4 DJS Analysis Tools

We developed two analysis tools for DJS programs. The
ï¬rst veriï¬es that a JavaScript program conforms to DJS.
The second extracts applied pi calculus models from DJS
programs, so that they may be veriï¬ed for security prop-
erties. For lack of space, we do not detail the implemen-
tation of these tools; both are available from our website.

662  22nd USENIX Security Symposium 

USENIX Association

10

# ./djst --check
x = function(s){return s.split(",")}; x("a,b");
Cannot type the following expression at file <stdio>,
line 1:38 to 1:46: x("a,b")
type <{"split":(string) -> â€™a}> was expected but got <string>.

# ./djst --pv >model.pv && proverif -lib djcl model.pv
(function(){ var mackey = _lib.secret("xxx")+"";

var _ = function(s){return _lib.hmac(s,mackey)};
return function(s){if(typeof s=="string") return _(s)}})

Typing successful, CPU time: 4ms.
--- Free variables ---
_lib:{"hmac":(string,string)->string,"secret":string->string}
Process:
{1}new fun_9: channel;
(

{2}!
{3}in(fun_9, ret_10: channel);
{4}new var_mackey: Memloc;
{5}let s_11: String = str_1 in

Figure 6: Screenshot of the DJS tool: ï¬rst a type-
checking error, then a (cut off) ProVerif translation.

4.1 Conformance Checker

We implement fully automatic type inference for the DJS
type system. Our tool can check if an input script is valid
DJS and provides informative error messages if it fails to
typecheck. Figure 6 shows a screenshot with a type error
and then the correct inferred type.

In our type system, an object such as {a:0, b:1}
can be assigned multiple types: {a:number,b:number},
{a:number}, {b:number} or {}. Subtyping induces a partial
order relation on the admissible types of an expression;
the goal of type inference is to compute the maximal ad-
missible type of a given expression.

inference that
type

To compute this type, we implement a restricted
variant of Hindleyâ€“Milner
incorpo-
rates width subtyping and infers
schemes.
For example,
the generalized type for the function
function f(x){return x[0]} is âˆƒÏ„. [Ï„]1 â†’ Ï„. Note the ex-
istential quantiï¬er in front of Ï„: function types are not
generalized, which would be unsound because of muta-
ble variables. Thus, if the type inference processes the
term f([1]), uniï¬cation will force Ï„ = number, and any
later attempt to use f(["a"]) will fail, while f([1,2]) will
be accepted.

The uniï¬cation of object type schemes yields the
union of the two sets of properties: starting from x : Ï„, af-
ter processing x.a + x.b, uniï¬cation yields Ï„ = {a : Ï„1,b :
Ï„2} and Ï„1 = Ï„2. Literal constructors are assigned their
maximal, ï¬xed object type {xi : Ti}âˆ—iâˆˆ[1..n]. Uniï¬cation of
an object type {X} with the ï¬xed {xi : Ti}âˆ—iâˆˆ[1..n] ensures
X âŠ† {xi : Ti}iâˆˆ[1..n].
Our tool uses type inference as a heuristic, and re-
lies on the soundness of the type checking rules of Sec-
tion 3.3 for its correctness. Our inference and uniï¬cation
algorithms are standard. We refer interested readers to
our implementation for additional details.

SrvApp1

. . .

SrvAppN

Library

UsrAgent1

. . .

UsrAgentN

p

g

a

e

t

g

e

credentials

C

C

o

o

l
i

c

k

k

S

t

o

r

ajaxRequest
setCookStor

HttpServer

net

HttpClient

DJS

httpSvReq

h t t p S v R e q

serverIdentities

cookies

storage

serverSessions

WebSpi

pageOrigin

Figure 7: WebSpi model and DJS components

4.2 Model Extraction
DJS is a useful starting point for a security component
developer, but defensiveness does not in itself guarantee
security: for example it does not say that a program will
not leak its secrets to the hosting webpage, say by expos-
ing them in its exported API. Moreover, security compo-
nents like those in Section 2 consist of several scripts ex-
changing encrypted messages with each other and with
other frames and websites. Such designs are complex
and prone to errors, analyzing their security thus requires
a detailed model of cryptography, the browser environ-
ment and the web attacker.

In prior work, the WebSpi library of the ProVerif tool
has been used to analyze the security of web applica-
tions [5, 6]. The main processes, channels and data ta-
bles of WebSpi are represented on Figure 7. UsrAgent
processes model the behavior of JavaScript running on a
page, while the other processes handle communications
and processing of server requests.

The advantage of this methodology is that an applica-
tion can be automatically veriï¬ed against entire classes
of web attackers. ProVerif can handle an unbounded
number of sessions, but may fail to terminate. If it ver-
iï¬es a model, it can serve to increase conï¬dence in the
security application. The disadvantage is that to model
a JavaScript component in WebSpi, a programmer nor-
mally has to write an applied pi calculus process for each
script by hand.

We developed a model extraction tool that automati-
cally generates user agent process models of components
written in the subset of DJS without loops, using a pro-
cess and data constructor library for cryptographic oper-
ations and serialization (matching our implemented DJS
libraries introduced in the next section).

Our generated processes may then be composed with
existing WebSpi models of the browser and (if neces-
sary) hand-written models of trusted servers and auto-
matically veriï¬ed. To support our translation, we ex-
tended the WebSpi model with a more realistic treatment
of JavaScript that allowed multiple processes to share the
same heap.

We do not fully detail our translation from DJS to the

USENIX Association  

22nd USENIX Security Symposium  663

11

applied pi calculus here for lack of space; it follows Mil-
nerâ€™s famous â€œfunctions as processesâ€ encoding of the
lambda calculus into the pi calculus [30]. Similar trans-
lations to ours have previously been deï¬ned (and proved
sound) for F# [12] and Java [4]. Our translation only
works for well-typed DJS programs that use our DJS li-
braries; it does not apply to arbitrary JavaScript.

DJS programs may preï¬x a function name by _lib to
indicate that the code of certain functions should not be
translated to applied pi and they must instead be treated
as trusted primitives. A typical example is cryptographic
functions, which get translated to symbolic functions.

Our translation recognizes two kinds of security an-
notations in source DJS programs. First, functions may
be annotated with security events; for example, the ex-
pression _lib.event(Send(a,b,x)) may be triggered be-
fore a uses a secret key shared with b to compute a MAC
of x. Second, functions may label certain values as se-
crets _lib.secret(x). Such annotations are reï¬‚ected in
the generated models and can be analyzed by ProVerif
to prove authentication and secrecy queries; we describe
complex components we veriï¬ed in Section 6.

5 Defensive Libraries

In this section, we present defensive libraries for cryptog-
raphy (DJCL), data encoding (DJSON), and JSON sig-
nature and encryption (JOSE). These libraries amount to
about two thousand lines of DJS code, veriï¬ed for de-
fensiveness using our conformance checker. Hence, they
can be relied upon even in hostile environments.

5.1 Defensive JavaScript Crypto Library
Our starting points for DJCL are two widely used
JavaScript libraries for cryptography: SJCL [37] (cover-
ing hashing, block ciphers, encoding and number gener-
ation) and JSBN (covering big integers, RSA, ECC, key
generation and used in the Chrome benchmark suite). We
rewrote and veriï¬ed these libraries in DJS.

Our implementation covers the following primitives:
AES on 256 bit keys in CBC and CCM/GCM modes,
SHA-1 and SHA-256, HMAC, RSA encryption and sig-
nature on keys up to 2048 bits with OAEP/PSS padding.
All our functions operate on byte arrays encoded as
strings; DJCL also includes related encoding and decod-
ing functions (UTF-8, ASCII, hexadecimal, and base64).
We evaluated the performance of DJCL using the
jsperf benchmark engine on Chrome 24, Firefox 18,
Safari 6.0 and IE 9. We found that our AES block func-
tion, SHA compression functions and RSA exponentia-
tion performed at least as fast as their SJCL and JSBN
counterparts, and sometimes even faster. Defensive cod-
ing is well suited for bit-level, self-contained crypto com-

putations, and JavaScript engines can easily optimize our
non-extensible arrays and objects.

On the other hand, when implementing high-level con-
structions such as HMAC or CCM encryption that oper-
ate on variable-length inputs, we pay a cost for not be-
ing able to access native objects in DJS. DJCL encodes
variable-length inputs in strings, since it cannot use
more efï¬cient but non-defensive objects like Int32Array.
Encoding and decoding UTF-8 strings without relying
on a pristine String.fromCharCode and String.charCodeAt
means that we need to use table lookups that are substan-
tially more expensive than the native functions. The re-
sulting performance penalty is highly dependent on the
amount of encoding, the browser and hardware being
used, but even on mobile devices, DJCL achieves en-
cryption and hashing rates upwards of 150KB/s, which is
sufï¬cient for most applications. Of course, performance
can be greatly improved in environments where proto-
types of the primordial String object can be trusted (for
instance, by using Object.freeze before any script is run).

5.2 Defensive JSON and JOSE
In most of our applications, the input string of a DJS pro-
gram represents a JSON object; our DJSON library seri-
alizes and parses such objects defensively for the internal
processing of such data within a defensive program.

DJSON.stringify takes a JSON object and a schema de-
scribing its structure (i.e. an object describing its DJS
type) and generates a serialized string. Deserializing
JSON strings generally requires the ability to create ex-
tensible objects. Instead, we rewrite DJSON.parse defen-
sively by requiring two additional parameters: the ï¬rst is
a schema representing the shape of the expected JSON
object; the second is a preallocated object of expected
shape that will be ï¬lled by DJSON.parse. Our typechecker
processes these schemas as type annotations and uses
them to infer types for code that uses these functions.

This approach imposes two restrictions. Since DJS
typing ï¬xes the length of objects, our library only works
with objects whose sizes are known in advance. This
restriction may be relaxed by using extensions of DJS
(described in our technical report [11]) that use algebraic
constructors for extensible objects and arrays. Also, at
present, we require users of the DJSON library to provide
the extra parameters (schemas, preallocated objects), but
we plan to extend our conformance checker to automati-
cally inject these parameters based on the inferred types
of the serialized and parsed JSON objects.

Combining DJCL and DJSON, we implemented a
family of emerging IETF standards for JSON cryptog-
raphy (JOSE), including JSON Web Tokens (JWT) and
JSON Web Encryption (JWE) [25]. Our library interop-
erates with other server-side implementations of JOSE

664  22nd USENIX Security Symposium 

USENIX Association

12

LOC Typing
Program
300ms
1728
DJCL
36ms
JOSE
160
7ms
Sec. AJAX 61
42ms
43
LastPass
Facebook
135
42ms
31ms
80
Conï¬Chair

PV LOC ProVerif
No Goal
114
No Goal
9
12s
243
21s
164
356
43s
25s
203

Table 2: Evaluation of DJS codebase

(notably those implementing OpenID Connect). Us-
ing JOSE, we can write security components that ex-
change encrypted and/or authenticated AJAX requests
and responses with trusted servers. More generally, we
can build various forms of secure RPC mechanisms be-
tween a DJS script and other principals (scripts, frames,
browser extensions, or servers.)

6 Applications

We revisit the password manager bookmarklet, single
sign-on script, and encrypted storage website examples
from Section 2 and evaluate how DJS can help avoid at-
tacks and improve conï¬dence in their security. For each
component, we show that DJS can achieve security goals
even stronger than those currently believed possible us-
ing standard browser security mechanisms. Table 2 sum-
marizes our codebase and veriï¬cation results.

6.1 Secret-Keeping Bookmarklets
Bookmarklets are fragments of JavaScript stored in a
bookmark that get evaluated in the scope of the active
page when they are clicked. Password manager book-
marklets (like LastPass Login, Verisign One-Click, Pass-
pack It) contain code that tries to automatically ï¬ll in
login forms (or credit card details) on the current page,
by retrieving encrypted data the user has stored on the
password managerâ€™s web server.

For example, the LastPass server authenticates the user
with a cookie (she must be currently logged in), authenti-
cates the host website with the Referer or Origin header,
and returns the login data encrypted with a secret key
(LASTPASS_RAND) that is unique to the bookmarklet and
embedded in its code. The bookmarklet then decrypts
the login data with its key and ï¬lls in the login form.

The code in these bookmarklets is typically not defen-
sive against same origin attacks; this leads to a family
of rootkit attacks, where a malicious webpage can fool
the bookmarklet into revealing its secrets [1]; indeed, we
found new variations of these attacks (Section 2) even
after the original designs were ï¬xed to use frames.

We wrote two,

improved versions of the LastPass

bookmarklet using DJS that prevent such attacks:

login data retrieved from the LastPass server.

â€¢ The ï¬rst uses DJCLâ€™s AES decryption to decrypt the
â€¢ The second uses DJCLâ€™s HMAC function to authen-
ticate the bookmarklet (via postMessage) to a frame
loaded from the LastPass origin; the frame then de-
crypts and reveals the login data to the host page.

Assuming the host page is correctly authenticated by
LastPass, both designs prevent rootkit attacks.

Moreover, both our bookmarklets guarantee a stronger
click authentication property. The bookmarklet key rep-
resents the intention of the user to release data to the cur-
rent page. If a script on the page could capture this key,
it would no longer need the bookmarklet; it could use the
password manager server directly to track (and login) the
user on subsequent visits, even if the user wished to re-
main anonymous, and say had erased her cookies for this
site. Instead, by protecting the key using DJS, and using
the key only once per click, both our designs guarantee
that the user must have clicked on the bookmarklet each
time her identity and data is released to the webpage.
Evaluation. Our bookmarklets are fully self-contained
DJS programs and with a trimmed-down version of
DJCL can ï¬t the 2048 bytes length limit of bookmarklets.
They require minimal changes to the existing LastPass
architecture. More radical redesigns are possible, but
even those would beneï¬t from being programmed in
DJS. We veriï¬ed our bookmarklets for defensiveness by
typing, and for key secrecy and click authentication by
using ProVerif. In ProVerif, we compose the models ex-
tracted from the bookmarklets with the WebSpi library
and a hand-written model for the LastPass server (and
frame).

Click authentication is an example of a security goal
that requires DJS; it cannot be achieved using frames
for example. The reason is that bookmarklets (unlike
browser extensions) cannot reliably create or commu-
nicate with frames without their messages being inter-
cepted by the page. They need secrets for secure com-
munication; only defensiveness can protect their secrets.

6.2 Script-level Token Access Control
The Facebook login component discussed in Section 2
keeps a secret access token and uses it to authenticate
user data requests to the Facebook REST API. How-
ever, this token may then be used by any script on the
host website, including social plugins from competitors
like Twitter and Google, and advertising libraries that
may track the user against her wishes. Can we restrict
the use of this access token only to selected scripts, say
only (ï¬rst-party) scripts loaded from the host website?
Browser-based security mechanisms, like iframes, can-
not help, since they operate at the origin level. Even CSP

USENIX Association  

22nd USENIX Security Symposium  665

13

666  22nd USENIX Security Symposium 

USENIX Association

policiesthatspecifywhichoriginscanprovidescriptstoawebpagecannotdifferentiatebetweenscriptsoncetheyareloadedintothepage.WeproposeanewdesignthatusesDJStoenforceï¬ne-grainedscript-levelaccesscontrolforwebsitese-cretslikeaccesstokensandCSRFtokens.WeimplementitbymodifyingtheFacebookJavaScriptSDKasfollows.WeassumethatthewebsitehasregisteredadedicatedTokenOrigin(e.g.open.login.yahoo.com)withFacebookwhereitreceivestheaccesstoken.Weassumethatthetokenisobtainedandstoredsecurelybythisorigin.Website Origin Facebook Server Token Origin Facebook API Trusted Scripts Access Token XHR Proxy DJS FB.api DJS header id, token API key FB.api() Thetokenoriginthenprovidesaproxyframetothemainwebsite(e.g.*.yahoo.com)thatonlyallowsautho-rizedscriptstousethetoken.Theframelistensforre-questssignedwithJWTusinganAPIkey;ifthesigna-tureisvalid,itwillinjecttheaccesstokenintotherequestandforwardittothenetwork(usingXHR,orJSONPforFacebook),andreturntheresult.Anusefulexten-siontothismechanismwhenprivacyisimportantistoacceptencryptedJWErequestsandencrypttheirresult(weleavethisoutforsimplicity).Onthemainwebsite,weuseaslightlymodiï¬edver-sionoftheFacebookSDKthathasnoaccesstotherealaccesstoken,butstillprovidesthesameclient-sideAPItothewebpage.Wereplacethefunctionthatperformsnetworkrequests(FB.api)withaDJSfunctionthatcon-tainsthesecretAPIkey,hencecanproducesignedre-questsfortheproxyframe.Thisfunctiononlyacceptsrequestsfrompre-authorizedscripts;itexpectsasitsar-gumentaserializedJSONWebToken(JWT)thatcon-tainstherequest,anidentiï¬erforthesourcescript,andasignaturewithascript-speciï¬ckey(inpractice,derivedfromtheAPIkeyandthescriptidentiï¬er).Ifthesig-natureisvalid,theAPIrequestissignedwiththeAPIkeyandforwardedtotheproxyframe.Thisfunctioncanalsoenforcescript-levelaccesscontrol;forinstance,itmayallowcross-originscriptstoonlyrequesttheusernameandproï¬lepicture,butnottopostmessages.Forthisdesigntowork,theAPIkeymustbefreshforeachuser,whichcanbeachievedusingtheuserâ€™sses-sionoracookie.Suchkeysshouldhavealifetimelimitcorrespondingtothecachelifetimeofthescriptsthatareinjectedwithsecrettokens.Onemayalsowanttoaddfreshnesstothesignedrequeststoavoidthembeingre-playedtotheproxyframe.Finally,each(trusted)scriptthatrequiresaccesstotheFacebookAPIisinjectedwithaDJSheaderthatpro-videsafunctionabletosigntherequeststoFB.apius-ingitsscriptidentiï¬erandasecrettokenderivedfromtheidentiï¬erandAPIkey.WeprovideasampleoftheDJScodeinjectedintotrustedscriptsbelow,forbasicFacebookAPIaccess(/me)withno(optional)parame-ters.Notethatonlythesign_requestfunctionisdefen-sive;weputitinthescopeofuntrustedcodeusingwithbecauseitpreventsthecallstackissuesofclosures:1with({sign_request:(function(){2vardjcl={/*...*/};3varid="me.js",tok="1f3c...";4var_=function(s){5returns=="/me"/*||s=="..."*/?6djcl.jwt.create(7djcl.djson.stringify({jti:id,req:s}),tok8):""};9returnfunction(s){10if(typeofs=="string")return_(s)}11})(),__proto__:null})12{13//Trustedscript14FB.api(sign_request("/me"),15function(r){alert("Hello,"+r.name)});16}Evaluation.Besidesallowingwebsitestokeeptheac-cesstokensecret,ourdesignletsthemcontrolwhichscriptscanuseitandhow(aformofAPIconï¬nement).Ofcourse,ascriptthatisgivenaccesstotheAPI(viaascriptkey)mayunintentionallyleakthecapability(butnotthekey),inwhichcaseourdesignallowstheweb-sitetoeasilyrevokeitsaccess(usingaï¬lterinFB.api).Ourproposalsigniï¬cantlyimprovesthesecurityofFace-bookclients,inwaysitwouldbedifï¬culttoreplicatewithstandardbrowsersecuritymechanisms.WeonlychangeonemethodfromtheFacebookAPIwhichaccountsforlessthan0.5%ofthetotalcode.OurdesignmaintainsDOMaccesstotheAPI,whichwouldbedifï¬culttoachievewithframes.WithouttakingDJCLintoaccount,eachoftheDJSfunctionsaddedtotrustedscriptsislessthan20linesofcode.Wetypecheckedourcodefordefensiveness,andveriï¬edwithProVerifthatitprovidestheexpectedscript-levelauthorizationguaran-tees,andthatitdoesnotleakitssecrets(APIkey,scripttokens)tothebrowser.6.3AnAPIforClient-sideEncryptionInSection2weshowedthatencryptedcloudstorageap-plicationsarestillvulnerabletoclient-sidewebattackslikeXSS(e.g.Conï¬Chair,Mega)thatcanstealtheirkeysandcompletelybreaktheirsecurity.Findingandelimi-natinginjectionattacksfromeverypageisnotalways14easy or feasible. Instead, we propose a robust design for
client-side crypto APIs secure despite XSS attacks.

First, we propose to use a defensive crypto library
rather than Java applets (Helios, Wuala, and Conï¬Chair)
or non-defensive JavaScript libraries (Mega, SpiderOak).
In the case of Java applets, this also has the advantage of
signiï¬cantly increasing the performance of the applica-
tion (DJCL is up to 100 times faster on large inputs) and
of reducing the attack surface by removing the Java run-
time from the trusted computing base.

Second, we propose a new encrypted local storage
mechanism for applications that need to store encryption
keys in the browser. This mechanism relies on the avail-
ability of an embedded session key that is speciï¬c to the
browser session and is embedded into code served by the
script server, but not given to the host page.

As a practical example, we show how to use both
these mechanisms to make the Conï¬Chair conference
management system more resilient against XSS attacks.
Conï¬Chair uses the following cryptographic API (types
shown for illustration):

derive_secret_key

//:(input:string,salt:string)->key:string

base64_encode, base64_decode //:string->string
encryptData, decryptData

//:(data:string,key:string)->string

encryptKeypurse//:(key:string,keypurse:json)->string
decryptKeypurse//:(key:string,string)->keypurse:json

When the user logs in, a script on the login page calls
derive_secret_key with the password to compute a se-
cret user key which is stored in localStorage. When the
user clicks on a particular document to download (a pa-
per or a review), the conference page downloads the en-
crypted PDF along with an encrypted keypurse for the
user. It decrypts the keypurse with the user key, stores it
in localStorage, and uses it to decrypt the PDF. The main
vulnerability here is that any same-origin script can steal
the user key (and keypurse) from local storage.

We write a drop-in replacement for this API in DJS.
Instead of returning the real user key and keypurse in
derive_secret_key and decryptKeypurse, our API returns
keys encrypted (wrapped) under a sessionKey. When
decryptData is called, it transparently unwraps the pro-
vided key, never exposing the user key to the page. Both
the encrypted user key and keypurse can be safely stored
in localStorage, because it cannot be read by scripts that
do not know sessionKey. We protect the integrity of these
keys with authenticated encryption.

Our design relies on a secure script server that can de-
liver defensive scripts embedded with session keys. Con-
cretely, this is a web service running in a trusted, isolated
origin (a subdomain like secure.confichair.org)
that accepts GET requests with a script name and a target
origin as parameters. It authenticates the target origin by

verifying the Origin header on the request, and may re-
ject requests for some scripts from some origins. It then
generates a fresh sessionKey, embeds it within the defen-
sive script and sends it back as a GET response. The
sessionKey remains the same for all subsequent requests
in the same browsing session (using cookies).
Evaluation. Our changes to the Conï¬Chair website
amount to replacing its Java applet with our own cryp-
tographic API and rewriting two lines of code from the
login page. The rest of the website works without further
modiï¬cation while enjoying a signiï¬cantly improved se-
curity against XSS attacks. Using ProVerif, we analyzed
our API (with an idealized model of the script server and
login page) and veriï¬ed that it does not leak the user
key, keypurse, or sessionKey. Our cryptographic API
looks similar to the upcoming Web Cryptography API
standard, except that it protects keys from same-origin
attackers, whereas the proposed API does not.

7 Related Work

Attacks similar to the ones we describe in Section 2 have
been reported before in the context of password manager
bookmarklets [1], frame busting defenses [35], single
sign-on protocols [6, 36, 41], payment processing com-
ponents [42], smartphone password managers [9], and
encrypted cloud storage [5, 10]. These works provide
further evidence for the need for defensive programming
techniques and automated analysis for web applications.
A number of works explore the use of frames and
inter-frame communication to isolate untrusted compo-
nents on a page or a browser extension by relying on
the same origin policy [2, 7, 8, 27, 44]. Our approach
is orthogonal; we seek to protect scripts against same-
origin attackers using defensive programming in stan-
dard JavaScript. Moreover, DJS scripts require fewer
privileges than frames (they cannot open windows, for
example) and unlike components written in full HTML,
DJS programs can be statically analyzed for security.

A variety of JavaScript subsets attempt to protect
trusted web pages from untrusted [20, 26, 28, 29, 31, 32,
34, 39]. Our goal is instead to run trusted components
within untrusted web pages, hence our security goals are
stronger, and our language restrictions are different. For
example, these subsets rely on ï¬rst-starter privilege, that
is, they only offer isolation on web pages where their
setup code runs ï¬rst so that it can restrict the code that
follows. Our scripts do not need such privileges.

[21] proves full abstraction for a compiler from f* (a
subset of ML) to JavaScript. Their theorem ensures that
programmers can reason about deployed f* programs en-
tirely in the semantics of the source language, ignoring
JavaScript-speciï¬c details. As such, their translation is

USENIX Association  

22nd USENIX Security Symposium  667

15

also robust against corruption of the JavaScript environ-
ment. However, there are also some signiï¬cant limita-
tions.
In particular, their theorems do not account for
HTML-level attackers who can, say, open frames and
call their functions. We also reported ï¬‚aws in their trans-
lation (since ï¬xed in their online version). In compar-
ison, our programs are written directly in a subset of
JavaScript and can defend themselves against stronger
threats, including full HTML adversaries that may exe-
cute before, after, and concurrently with our programs.

Dynamic information ï¬‚ow analyses for various sub-
sets of JavaScript [3, 17, 24] enforce a security property
called noninterference. Our static type system enforces
defensiveness and we analyze security by model extrac-
tion. Relating defensiveness to noninterference remains
future work; we conjecture that DJS may be more suit-
able than JavaScript to static information ï¬‚ow analysis.

8 Conclusion

Given the complexity and heterogeneity of the web pro-
gramming environment and the wide array of threats it
must contend with, it is difï¬cult to believe that any web
application can enjoy formal security guarantees that do
not break easily in the face of concerted attack. Instead
of relying on the absence of web vulnerabilities, this pa-
per presents a defense-in-depth strategy. We start from a
small hardened core (DJS) that makes minimal assump-
tions about the browser and JavaScript runtime, and then
build upon it to obtain defensive security for critical com-
ponents. We show how this strategy can be applied to ex-
isting applications, with little change to their code but a
signiï¬cantly increase in their security. We believe our
methods scale, and lifting these results to protect full
websites that use HTML and PHP is ongoing work.

Acknowledgements The authors would like to thank
David Wagner, Nikhil Swamy and the anonymous re-
viewers for their helpful comments leading to signiï¬-
cant improvements to this paper. We would also like to
acknowledge the Mozilla and Facebook security teams
for prompt and constructive discussions about our at-
tacks. Bhargavan and Delignat-Lavaud are supported by
the ERC Starting Grant CRYSP. Maffeis is supported by
EPSRC grant EP/I004246/1.

References

[1] B. Adida, A. Barth, and C. Jackson. Rootkits for

JavaScript environments. In WOOT, 2009.

[2] D. Akhawe, P. Saxena, and D. Song. Privilege sep-
aration in HTML5 applications. In USENIX Secu-
rity, 2012.

[3] T. Austin and C. Flanagan. Multiple facets for dy-
namic information ï¬‚ow. In POPL, pages 165â€“178,
2012.

[4] M. Avalle, A. Pironti, D. Pozza, and R. Sisto.
JavaSPI: A framework for security protocol imple-
mentation.
International Journal of Secure Soft-
ware Engineering, 2:34â€“48, 2011.

[5] C. Bansal, K. Bhargavan, A. Delignat-Lavaud, and
S. Maffeis. Keys to the cloud: Formal analysis
and concrete attacks on encrypted web storage. In
POST, 2013.

[6] C. Bansal, K. Bhargavan, and S. Maffeis. Discov-
ering concrete attacks on website authorization by
formal analysis. In CSF, pages 247â€“262, 2012.

[7] A. Barth, C. Jackson, and W. Li. Attacks on
In W2SP,

JavaScript mashup communication.
2009.

[8] A. Barth, C. Jackson, and J.C. Mitchell. Securing
browser frame communication. In USENIX Secu-
rity, 2008.

[9] A. Belenko and D. Sklyarov.

â€œSecure pass-
word managersâ€ and â€œMilitary-grade encryptionâ€
on smartphones: Oh, really? Technical report, El-
comsoft Ltd., 2012.

[10] K. Bhargavan and A. Delignat-Lavaud. Web-based
attacks on host-proof encrypted storage. In WOOT,
2012.

[11] K. Bhargavan, A. Delignat-Lavaud, and S. Maf-
feis. Defensive JavaScript website with testbed,
technical report and supporting materials.
http:
//www.defensivejs.com, 2013.

[12] K. Bhargavan, C. Fournet, A. D. Gordon, and
S. Tse. Veriï¬ed interoperable implementations of
security protocols. In CSFW, pages 139â€“152, 2006.

[13] B. Blanchet and B. Smyth.

ProVerif: Auto-
matic Cryptographic Protocol Veriï¬er, User Man-
ual and Tutorial.
http://www.proverif.inria.fr/
manual.pdf.

[14] P. Canning, W. Cook, W. Hill, W. Olthoff, and
J. Mitchell. F-bounded polymorphism for object-
oriented programming. In FPCA, pages 273â€“280,
1989.

[15] L. Cardelli.

Extensible records in a pure cal-
culus of subtyping.
In In Theoretical Aspects
of Object-Oriented Programming, pages 373â€“425.
MIT Press, 1994.

668  22nd USENIX Security Symposium 

USENIX Association

16

[16] D. Crockford. ADsafe: Making JavaScript safe for

advertising. http://www.adsafe.org/, 2008.

[17] W. De Groef, D. Devriese, N. Nikiforakis, and
F. Piessens. FlowFox: a web browser with ï¬‚exi-
ble and precise information ï¬‚ow control. In CCS,
pages 748â€“759, 2012.

[18] D. Dolev and A.C. Yao. On the security of public
key protocols. IEEE Transactions on Information
Theory, ITâ€“29(2):198â€“208, 1983.

[19] M. Finifter, A. Mettler, N. Sastry, and D. Wagner.
Veriï¬able functional purity in Java. In CCS, pages
161â€“174. ACM, 2008.

[20] M. Finifter, J. Weinberger, and A. Barth. Preventing
Capability Leaks in Secure JavaScript Subsets. In
BDSS, 2010.

[21] C. Fournet, N. Swamy, J. Chen, P. Dagand, P. Strub,
Fully abstract compilation to

and B. Livshits.
JavaScript. In POPLâ€™13, 2013.

[22] P. Haack.

JSON hijacking. http://hhacked.com/

2009/06/25/json-hijacking.aspx, 2009.

[23] D. Hardt. The OAuth 2.0 authorization framework.

IETF RFC 6749, 2012.

[24] D. Hedin and A. Sabelfeld. Information-ï¬‚ow secu-
rity for a core of JavaScript. In CSF, pages 3â€“18,
2012.

[25] IETF. JavaScript Object Signing and Encryption
http://tools.ietf.org/wg/

(JOSE), 2012.
jose/.

[26] S. Maffeis, J. C. Mitchell, and A. Taly.

Isolating
JavaScript with ï¬lters, rewriting, and wrappers. In
ESORICSâ€™09, 2009.

[27] L. Meyerovich, A. Porter Felt, and M. Miller. Ob-
In

ject views: Fine-grained sharing in browsers.
WWW, 2010.

[28] L. Meyerovich and B. Livshits. ConScript: Spec-
ifying and enforcing ï¬ne-grained security policies
for JavaScript in the browser. In IEEE S&P, 2010.

[29] J. Mickens and M. Finifter. Jigsaw: Efï¬cient, low-
effort mashup isolation. In USENIX Web Applica-
tion Development, 2012.

[30] R. Milner. Functions as processes.

In Automata,
Languages and Programming, volume 443, pages
167â€“180. 1990.

[31] P. Phung, D. Sands, and D. Chudnov. Lightweight

self-protecting JavaScript. In ASIACCS, 2009.

[32] J. Politz, S. Eliopoulos, A. Guha, and S. Krish-
namurthi. ADsafety: Type-based veriï¬cation of
JavaScript sandboxing. In USENIX Security, 2011.

[33] F. Pottier. Type inference in the presence of sub-
typing: from theory to practice. Research Report
3483, INRIA, September 1998.

[34] C. Reis, J. Dunagan, H. Wang, O. Dubrovsky, and
S. Esmeir. BrowserShield: Vulnerability-driven ï¬l-
tering of dynamic HTML. ACM Transactions on
the Web, 1(3), 2007.

[35] G. Rydstedt, E. Bursztein, D. Boneh, and C. Jack-
son. Busting frame busting: a study of clickjacking
vulnerabilities at popular sites. In W2SPâ€™10, 2010.

[36] J. Somorovsky, A. Mayer, A. Worth, J. Schwenk,
M. Kampmann, and M. Jensen. On breaking
SAML: Be whoever you want to be.
In WOOT,
2012.

[37] E. Stark, M. Hamburg, and D. Boneh. Symmetric
cryptography in JavaScript. In ACSAC, pages 373â€“
381, 2009.

[38] B. Sterne and A. Barth. Content Security Policy

1.0. W3C Candidate Recommendation, 2012.

[39] A. Taly, Â´U. Erlingsson, J. C. Mitchell, M. Miller,
and J. Nagra. Automated analysis of security-
critical JavaScript APIs. In IEEE S&P, 2011.

[40] Google Caja Team. A source-to-source translator
for securing JavaScript-based web. http://code.
google.com/p/google-caja/.

[41] R. Wang, S. Chen, and X. Wang. Signing me
onto your accounts through facebook and google:
A trafï¬c-guided security study of commercially de-
ployed single-sign-on web services. In IEEE S&P,
pages 365â€“379. IEEE Computer Society, 2012.

[42] R. Wang, S. Chen, X. Wang, and S. Qadeer. How
to shop for free online - security analysis of cashier-
as-a-service based web stores. In IEEE S&P, pages
465â€“480, 2011.

[43] M. Zalewski. The Tangled Web. No Starch Press,

November 2011.

[44] L. Zhengqin and T. Rezk. Mashic compiler:
Mashup sandboxing based on inter-frame commu-
nication. 2012.

USENIX Association  

22nd USENIX Security Symposium  669

17

