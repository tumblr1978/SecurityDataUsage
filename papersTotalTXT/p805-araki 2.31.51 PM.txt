High-Throughput Semi-Honest Secure Three-Party

Computation with an Honest Majority

Toshinori Araki

NEC Corporation, Japan
t-araki@ek.jp.nec.com

Jun Furukawa

NEC Corporation, Japan

j-furukawa@ay.jp.nec.com

Bar-Ilan University, Israel

Yehuda Lindell∗
lindell@biu.ac.il

Ariel Nof∗

Bar-Ilan University, Israel
nofdinar@gmail.com

ABSTRACT
In this paper, we describe a new information-theoretic proto-
col (and a computationally-secure variant) for secure three-
party computation with an honest majority. The proto-
col has very minimal computation and communication; for
Boolean circuits, each party sends only a single bit for every
AND gate (and nothing is sent for XOR gates). Our protocol
is (simulation-based) secure in the presence of semi-honest
adversaries, and achieves privacy in the client/server model
in the presence of malicious adversaries.

On a cluster of three 20-core servers with a 10Gbps con-
nection, the implementation of our protocol carries out over
1.3 million AES computations per second, which involves
processing over 7 billion gates per second. In addition, we
developed a Kerberos extension that replaces the ticket-
granting-ticket encryption on the Key Distribution Center
(KDC) in MIT-Kerberos with our protocol, using keys/ pass-
words that are shared between the servers. This enables the
use of Kerberos while protecting passwords. Our implemen-
tation is able to support a login storm of over 35,000 logins
per second, which suﬃces even for very large organizations.
Our work demonstrates that high-throughput secure com-
putation is possible on standard hardware.

INTRODUCTION

1.
1.1 Background

In the setting of secure computation, a set of parties with
private inputs wish to compute a joint function of their
inputs, without revealing anything but the output. Pro-
tocols for secure computation guarantee privacy (meaning
∗
Supported by the European Research Council under the ERC con-
solidators grant agreement n. 615172 (HIPS) and by the BIU Center
for Research in Applied Cryptography and Cyber Security in conjunc-
tion with the Israel National Cyber Bureau in the Prime Minister’s
Oﬃce.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’16, October 24-28, 2016, Vienna, Austria
c(cid:13) 2016 ACM. ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978331

Kazuma Ohara

NEC Corporation, Japan

k-ohara@ax.jp.nec.com

that the protocol reveals nothing but the output), correct-
ness (meaning that the correct function is computed), and
more. These security guarantees are to be provided in the
presence of adversarial behavior. There are two classic ad-
versary models that are typically considered: semi-honest
(where the adversary follows the protocol speciﬁcation but
may try to learn more than allowed from the protocol tran-
script) and malicious (where the adversary can run any arbi-
trary polynomial-time attack strategy). In the information-
theoretic model, security is obtained unconditionally and
even in the presence of computationally unbounded adver-
saries. In contrast, in the computational model, security is
obtained in the presence of polynomial-time adversaries and
relies on cryptographic hardness assumptions.

Despite its stringent requirements, it has been shown that
any polynomial-time functionality can be securely computed
with computational security [25, 12, 3] and with information-
theoretic security [2, 8]. These results hold both for semi-
honest and malicious adversaries, but an honest majority
must be assumed in order to obtain information-theoretic se-
curity even for semi-honest adversaries. There are two main
approaches to secure computation protocols: the secret- shar-
ing approach (followed by [2, 8, 12]) works by having the
parties interact for every gate of the circuit, whereas the
garbled-circuit approach (followed by [25, 3]) works by hav-
ing the parties construct an encrypted version of the circuit
which can be computed at once. Both approaches have im-
portance and have settings where they perform better than
the other. On the one hand, the garbled-circuit approach
yields protocols with a constant number of rounds. Thus,
in high-latency networks, they far outperform secret-sharing
based protocols which have a number of rounds linear in the
depth of the circuit being computed. On the other hand,
protocols based on secret-sharing typically have low band-
width and send small messages per gate, in contrast to gar-
bled circuits that are large and costly in bandwidth. This
limits the potential throughput of protocols following the
garbled-circuit approach, even when run in very low-latency
networks. Note that information-theoretic protocols typi-
cally rely on simple operations making them fast (but no
constant-round protocol for this setting is known to exist
and this is conjectured to be hard if not impossible [14]).

Another question determining the type of protocol to use
is whether or not high throughput or low latency is the goal.
If low latency is needed (and the circuit being computed is
deep), then constant-round protocols like [25] outperform
secret-sharing based protocols, even on very fast networks.

805However, these same protocols fail to achieve high though-
put due to the large bandwidth incurred.

Due to this situation, it is important to develop protocols
for low and high latency networks, with better response time
and/or throughput.
1.2 Our Results

In this paper, we focus on the question of achieving se-
cure computation with very high throughput on a fast net-
work (without utilizing special-purpose hardware beyond
the widespread Intel AES-NI and AVX instruction sets).
The challenge in achieving this is both on the computational
and network levels. Speciﬁcally, a protocol achieving very
high throughput would need to both be very simple compu-
tationally and also utilize very little bandwidth. Achieving
both of these tasks is challenging. The BGW protocol [2]
for semi-honest adversaries requires each party to send 3
ﬁeld elements to each other party per multiplication gate,
whereas the Sharemind protocol [4, 5, 27] (in its latest op-
timized version [16]) requires each party to send 5 elements
per multiplication gate, and further reduces the number of
ﬁeld multiplications. For Boolean circuits and 3 parties, this
translates to sending just 12 bits per AND gate in BGW and
sending just 10 bits per gate in Sharemind.

A new protocol. We describe a new three-party proto-
col that is both extremely simple and has seemingly optimal
bandwidth. Our protocol is suitable for arithmetic circuits
over any ﬁeld or over the ring modulo 2n. Addition gates
require local addition only, and multiplication gates require
that each party send just a single ﬁeld/ring element to one
other party. In the Boolean case, this means that each party
transmits a single bit only per AND gate.1 Furthermore,
the computation in our protocol is extraordinarily simple:
in the case of Boolean circuits, each party carries out a sin-
gle XOR operation per XOR gate, and 2 AND and 3 XOR
operations per AND gate. Since all operations are merely
XOR and AND, this also lends itself to parallelization on
standard computers (in particular, XOR and AND over 128
bit registers can be carried out in the same time as for a
single bit using Intel intrinsics).

Security. We prove that our protocol is secure in the
presence of semi-honest adversaries with at most one cor-
rupted party, under the standard simulation-based deﬁni-
tions. The basis of our protocol is information theoretic
(and in fact perfectly secure). However, we save on commu-
nication by generating correlated randomness computation-
ally, and therefore our overall protocol is computationally
secure. (This combination enables us to achieve simple op-
erations and save on additional bandwidth.) In addition to
the above, we also consider a client/server model where any
number of clients send shares of their inputs to 3 servers that
carry out the computation for the clients and return the
results to them (without learning anything). This model
makes sense for “outsources secure computation services”
and indeed is the business model of Cybernetica. We show
that in this model, our protocol actually achieves privacy in
the presence of malicious adversaries, meaning that a single
malicious server cannot learn anything about the input or
output. (We stress that this notion is strictly weaker than
simulation-based security in the presence of malicious ad-

1

This is “seemingly” optimal in terms of bandwidth, but this has not

been proven and seems hard to do so; see [14].

versaries, and in particular, does not guarantee correctness.
Nevertheless, it does guarantee that privacy is not breached
even if one of the servers behaves maliciously.)
Number of parties. As in Sharemind [4, 5], our proto-
col is speciﬁcally designed for 3 parties with at most one
corrupted. This is unlike BGW [2] that works for any num-
ber of parties with an honest majority. An important open
question left by this paper is the design of a protocol with
comparable complexity that works for any number of par-
ties. This seems to be very challenging, based on attempts
that we have made to extend our protocol.
Experimental results. We implemented our new pro-
tocol for Boolean circuits in C++ and using standard op-
timizations. In order to take advantage of the very simple
operations required in our protocol, we used Intel intrinsics
in order to carry out many executions in parallel. This is
described in detail in Section 5.1. We ran our experiments
on a cluster of three nodes, each with two 10-core Intel Xeon
(E5-2650 v3) processors and 128GB RAM, connected via a
10Gbps Ethernet. (We remark that little RAM was utilized
and thus this is not a parameter of importance here.) We
carried out two main experiments, both based on securely
computing the AES circuit on shared keys.

First, we computed AES in counter mode, with the aim
of obtaining maximal throughput. Using the full power of
the cluster (all cores), we computed over 1.3 million AES
operations per second. Furthermore, utilizing a single core
we achieved 100,000 AES operations per second, and utiliz-
ing 10 cores we achieved amost 1 million AES operations
per second. As we will show below in Section 1.3, this way
outperforms all previous protocols of this type.

Second, we wished to demonstrate that this type of proto-
col can be incorporated into a real system. We chose to in-
tegrate our protocol into a Kerberos KDC in order to carry
out Ticket-Granting-Ticket encryption without any single
server holding the encryption key (whether it be a server’s
key or user’s hashed password). Such an architecture pro-
tects against administrators stealing passwords, or an at-
tacker who breaches the network being able to steal all users’
passwords. (We stress that in Kerberos, the raw password
is never used so once the hashed password is stolen the at-
tacker can impersonate the user.) We obtained a latency of
110ms on the server and 232ms on the client (over a LAN)
for the entire Kerberos login (excluding database lookup).
Given that this is for the purpose of user authentication,
this is well within the acceptable range. In addition, we are
able to support a login storm of over 35,000 user authen-
tications per second, which is suﬃcient even for very large
organizations.

Our results demonstrate that secure computation can be
used to solve large-scale problems in practice (at least, for
the cases that semi-honest security or privacy for a malicious
adversary suﬃces).
1.3 Related Work

We compare our results with previously reported results
on secure AES computation for 3 parties with an honest
majority and semi-honest adversaries; see Table 1.

We stress that this table gives only very partial informa-
tion since diﬀerent hardware was used for each; we provide
it to show the progress made and where we ﬁt into it. How-
ever, fortunately, the setup used by us is almost the same
as that of the latest Sharemind results in [22] (using op-

806timized code that was completely rewritten), and we now
provide an in-depth comparison to it. The benchmarking
in [22] was carried out between three computers with two 8-
core Intel Xeon (E5-2640 v3) processors and 128GB RAM,
connnected via a 10Gbps Ethernet (this conﬁguration is de-
scribed in [16] and by personal communication is that used
in [22]), which is almost identical to our conﬁguration de-
scribed above. The number that we provide in Table 1 for
this work is when utilizing 16 cores, and thus this is an
almost identical conﬁguration as Sharemind [22] (with 20
cores we achieve 1,324,117 AES operations per second). Ob-
serve that our latency (response time) is 70% of [23] and we
achieve a throughput that is 14 times faster than [22] (and
so over an order of magnitude improvement). In fact, using
a single core and a 1Gbps connection, we achieve approxi-
mately 100,000 AES operations per second (and latency of
only 129ms); thus we can outperform the best Sharemind
results on a very basic setup.

Year
2010
2012
2013
2016
2016
2016

Ref.
[10]
[18]
[19]

[23, Table 5.3]

[22]

Latency Throughput

2000s

14.28ms
323ms
223ms

-

-

320
3450
25,000
90,000

this work

166ms

1,242,310

Table 1: Reported times for semi-honest 3-party computation &
honest majority; the throughput is measured in AES computa-
tions per second (the last two rows with similar conﬁgurations).

We remark that other work on garbled circuits (e.g., two-
party Yao with semi-honest adversaries) achieves much lower
latency (e.g., 16ms reported in [13]). However, each garbled
AES circuit is of size at least 1.3Mb (using the latest half-
gates optimization [26]), not taking into account additional
messages that are sent. It is therefore physically impossi-
ble to go beyond 7500 AES computations per second on a
10Gbps network (where we achieve 1.4 million).
In addi-
tion, the two-party GMW approach using eﬃcient oblivious
transfer (OT) extensions is blocked by the speed of the OTs
(with two OTs required per gate). Considering the commu-
nication bottleneck, each OT requires transmitting a mini-
mum of 128 bits. Thus, the communication is approximately
the same as with a garbled circuit. (The fastest known im-
plementation [15] can process 5 million OTs per second on a
1Gbps network giving under 500 AES computations per sec-
ond. This is not far from optimal assuming linear scale-up
on a 10Gbps network.) Of course, we require an additional
server, in contrast to the Yao and GMW protocols.

2. THE NEW PROTOCOL

In this section, we describe our new protocol for three par-
ties. Our protocol works for arithmetic circuits over the ring
modulo 2n with Boolean circuits being a special case (with
n = 1). The protocol uses only very simple ring addition and
multiplication operations, which in the Boolean case reduces
simply to bitwise AND and XOR. In addition, the protocol
has very low communication: a single ring element is sent
per multiplication gate and there is no communication for
addition gates. In the Boolean case, we therefore have that
the only communication is a single bit per AND gate.

Correlated randomness. Our protocol assumes that
for every multiplication gate the three parties P1, P2, P3 are
given correlated randomness in the form of random ring ele-
ments x1, x2, x3 under the constraint that x1 + x2 + x3 = 0.
We show how this can be achieved in practice with great
eﬃciency using AES. (Thus, our protocol is information-
theoretically secure with perfect correlated randomness, but
the actual implementation is computationally secure due to
the use of AES to generate the correlated randomness.)
2.1 Securely Computing Boolean Circuits

In order to simplify the exposition, we begin by describing
the protocol for the special case of Boolean circuits with
AND and XOR gates. We assume that the parties P1, P2, P3
are able to obtain random x1, x2, x3 ∈ {0, 1} such that x1 ⊕
x2 ⊕ x3 = 0.
Secret sharing. We deﬁne a 2-out-of-3 secret sharing
bit v, the dealer chooses three random bits x1, x2, x3 ∈ {0, 1}
under the constraint that x1 ⊕ x2 ⊕ x3 = 0. Then:

(cid:1)-sharing, as follows. In order to share a

scheme, denoted(cid:0)3

2

• P1’s share is the pair (x1, a1) where a1 = x3 ⊕ v.
• P2’s share is the pair (x2, a2) where a2 = x1 ⊕ v.
• P3’s share is the pair (x3, a3) and a3 = x2 ⊕ v.

(cid:1)-
In order to see that the result constitutes a valid (cid:0)3

It is clear that no single party’s share reveals anything about
v. In addition, any two shares suﬃce to obtain v; e.g., given
x1, x2, a1, a2 we can compute v = a2 ⊕ x1.
XOR (addition) gates. Let (x1, a1), (x2, a2), (x3, a3) be
a secret sharing of v1, and let (y1, b1), (y2, b2), (y3, b3) be a
secret sharing of v2. Then, in order to compute a secret
sharing of v1 ⊕ v2, each Pi locally computes (zi, ci) with
zi = xi ⊕ yi and ci = ai ⊕ bi (no communication is needed).
sharing of v1 ⊕ v2, observe ﬁrst that z1 ⊕ z2 ⊕ z3 = 0 (since
both x1 ⊕ x2 ⊕ x3 = 0 and y1 ⊕ y2 ⊕ y3 = 0). Next, observe
that for every i ∈ {1, 2, 3} it holds that ci = zi−1 ⊕ (v1 ⊕ v2)
where i−1 = 3 when i = 1; e.g., we have c1 = a1⊕b1 = x3⊕
v1⊕y3⊕v2 = (x3⊕y3)⊕(v1⊕v2) = z3⊕(v1⊕v2). Thus, this
constitutes a sharing of v1 ⊕ v2 with randomness z1, z2, z3.
AND (multiplication) gates. We now show how the par-
ties can compute AND (equivalently, multiplication) gates;
this subprotocol requires each party to send a single bit only.
The protocol works in two phases: in the ﬁrst phase the par-

ties compute a simple (cid:0)3
(cid:1) XOR-sharing of the AND of the
input bits, and in the second phase they convert the (cid:0)3
(cid:1)-
sharing into the above-deﬁned(cid:0)3
pute(cid:0)3
1. Step 1 – compute (cid:0)3

Let (x1, a1), (x2, a2), (x3, a3) be a secret sharing of v1, and
let (y1, b1), (y2, b2), (y3, b3) be a secret sharing of v2. We as-
sume that the parties P1, P2, P3 hold correlated randomness
α, β, γ, respectively, where α ⊕ β ⊕ γ = 0. The parties com-

(cid:1)-shares of v1 · v2 = v1 ∧ v2 as follows (from here on,

we will denote multiplication of a and b by simply ab):

(cid:1)-sharing:

(cid:1)-sharing.

2

2

3

3

3

2

(a) P1 computes r1 = x1y1⊕a1b1⊕α, and sends r1 to P2.
(b) P2 computes r2 = x2y2⊕a2b2⊕β, and sends r2 to P3.
(c) P3 computes r3 = x3y3⊕a3b3⊕γ, and sends r3 to P1.

These messages are computed and sent in parallel.

8072. Step 2 – compute(cid:0)3
construct a(cid:0)3

(cid:1)-sharing: In this step, the parties
(cid:1)-sharing and

(cid:1)-sharing from their given(cid:0)3

2

2

3

the messages sent in the previous step. This requires local
computation only.
(a) P1 stores (z1, c1) where z1 = r1 ⊕ r3 and c1 = r1.
(b) P2 stores (z2, c2) where z2 = r2 ⊕ r1 and c2 = r2.
(c) P3 stores (z3, c3) where z3 = r3 ⊕ r2 and c3 = r3.

(cid:1) sharing of v1v2, meaning

ﬁned in Step 1 are indeed a (cid:0)3

Explanation of Step 1: We now show that r1, r2, r3 de-
that r1 ⊕ r2 ⊕ r3 = v1 ∧ v2. Observe ﬁrst that:
a1b1 = (x3 ⊕ v1)(y3 ⊕ v2) = x3y3 ⊕ x3v2 ⊕ y3v1 ⊕ v1v2 (1)
and similarly a2b2 = x1y1 ⊕ x1v2 ⊕ y1v1 ⊕ v1v2, and a3b3 =
x2y2 ⊕ x2v2 ⊕ y2v1 ⊕ v1v2. Thus,
r1 ⊕ r2 ⊕ r3

3

= (x1y1 ⊕ a1b1 ⊕ α) ⊕ (x2y2 ⊕ a2b2 ⊕ β) ⊕ (x3y3 ⊕ a3b3 ⊕ γ)
= x1y1 ⊕ x2y2 ⊕ x3y3 ⊕ a1b1 ⊕ a2b2 ⊕ a3b3
= x1y1 ⊕ x2y2 ⊕ x3y3 ⊕ (x3y3 ⊕ x3v2 ⊕ y3v1 ⊕ v1v2)

⊕ (x1y1 ⊕ x1v2 ⊕ y1v1 ⊕ v1v2)
⊕ (x2y2 ⊕ x2v2 ⊕ y2v1 ⊕ v1v2)

= (x1 ⊕ x2 ⊕ x3)v2 ⊕ (y1 ⊕ y2 ⊕ y3)v1 ⊕ v1v2 = v1v2

is a valid(cid:0)3

(cid:1)-sharing of v1v2 according to our deﬁnition, we

where the second equality is because α⊕β⊕γ = 0, the third
equality is from the equivalences of a1b1, a2b2, a3b3 above
(see Eq. (1)), the fourth equality is by cancelling repeated
values and rearranging the remainder, and the last equality
is because x1 ⊕ x2 ⊕ x3 = y1 ⊕ y2 ⊕ y3 = 0.
Explanation of Step 2:
In order to show that the result
need to show that z1, z2, z3 are such that z1 ⊕ z2 ⊕ z3 = 0,
and that c1, c2, c3 are of the deﬁned form.
First, z1 ⊕ z2 ⊕ z3 = (r1 ⊕ r3) ⊕ (r2 ⊕ r1) ⊕ (r3 ⊕ r2) = 0.
Second, observe that since c1 ⊕ c2 ⊕ c3 = r1 ⊕ r2 ⊕ r3 = v1v2
(as shown above), it holds that c1 = r1 = v1v2 ⊕ r2 ⊕ r3.
However, r2 ⊕ r3 = z3 (by the protocol deﬁnition) and thus
c1 = v1v2 ⊕ z3, as required. A similar calculation shows the
equality for c2 and c3 as well.

2

The above explanation shows that the gate computation
“works” in the sense that the invariant of the format of the
shares is preserved after every gate is computed. The fact
that the protocol is secure is proved later in Section 3.
The protocol. The full 3-party protocol works in the nat-
ural way. The parties ﬁrst share their inputs using the secret
sharing method. They then compute each XOR and AND
gate in the circuit according to a predetermined topological
ordering fo the circuit. Finally, the parties reconstruct their
output on the output wires. (In the client/server model, ex-
ternal clients send the three parties sharings of their input
according, and the three parties then compute the circuit in
the same way on the shares received.)

Observe that each party communicates with exactly one
other party only. This property also holds for the protocol
of Sharemind [4, 5]. However, our secret-sharing scheme and
multiplication protocol are completely diﬀerent.
2.2 Generating Correlated Randomness
Our protocol relies on the fact that the parties hold ran-
dom bits α, β, γ ∈ {0, 1} such that α ⊕ β ⊕ γ = 0 for every
AND gate.
In this section, we show how the parties can
eﬃciently generate such α, β, γ.

Information-theoretic correlated randomness.
It is
possible to securely generate correlated randomness with
perfect security by having each party Pi simply choose a
random ρi ∈ {0, 1} and send it to Pi+1 (where P3 sends
to P1). Then, each party takes its random bit to be the
XOR of the bit it chose and the bit it received: P1 computes
α = ρ3 ⊕ ρ1, P2 computes β = ρ1 ⊕ ρ2 and γ = ρ2 ⊕ ρ3.
Observe that α + β + γ = 0 as required. In addition, if P1
is corrupted, then it knows nothing about β and γ except
that β ⊕ γ = α. This is because β and γ both include ρ2 in
their computation and this is unknown to P1. A similar ar-
gument holds for a corrupted P2 or P3. Despite the elegance
and simplicity of this solution, we use a diﬀerent approach.
This is due to the fact that this would double the commu-
nication per AND gate; it is true that this is still very little
communication. However, given that communication is the
bottleneck, it would halve the throughput.

Computational correlated randomness. We now show
how it is possible to securely compute correlated randomness
computationally without any interaction beyond a short ini-
tial setup. This enables us to maintain the current situa-
tion where parties need only transmit a single bit per AND
gate. This method is similar to that of the PRSS subprotocol
in [9], but simpler since Shamir sharing is not needed. Let
κ be the security parameter, and let F : {0, 1}κ × {0, 1}κ →
{0, 1} be a pseudorandom function outputting a single bit.
1. Init:

(a) Each Pi chooses a random ki ∈ {0, 1}κ.
(b) Party P1 sends k1 to P3, party P2 sends k2 to P1

and party P3 sends k3 to k1.

P1 holds k1, k2, P2 holds k2, k3 and P3 holds k3, k1.
2. GetNextBit: Given a unique identiﬁer id ∈ {0, 1}κ,

(a) P1 computes α = Fk1 (id) ⊕ Fk2 (id).
(b) P2 computes β = Fk2 (id) ⊕ Fk3 (id).
(c) P3 computes γ = Fk3 (id) ⊕ Fk1 (id).

Observe that α⊕ β ⊕ γ = 0. Furthermore, P1 does not know
k3 which is used to generate β and γ. Thus, β and γ are
pseudorandom to P1, under the constraint that β ⊕ γ = α.
In practice, the id can be a counter that all parties locally
increment at every call to GetNextBit.
2.3 The Ring Modulo 2n and Fields

Our protocol above works for Boolean circuits. However,
in some cases arithmetic circuits are far more eﬃcient. In
this section, we show how to generalize the protocol above
to the general case of the ring modulo 2n and arbitrary ﬁelds
of size greater than 2. We describe the protocol for the ring
modulo 2n; it is clear that everything holds for arbitrary
ﬁnite ﬁelds and rings in which 3−1 exists. (The only thing
that is needed is to be able to divide by 3 which is deﬁned by
adding the unity to itself 3 times. This is possible in the ring
modulo 2n since gcd(3, 2n) = 1, and is always possible in a
ﬁeld.) From here-on in this section, all arithmetic is mod2n.
We remark that when taking n = 1 we have that addition
(and subtraction) is the same as XOR, and multiplication is
the same as AND. In this case, the protocol here is exactly
that described in Section 2.1.

(cid:1)-secret sharing. In order to share an element v mod 2n

the dealer chooses three random elements x1, x2, x3 ∈ Z2n

(cid:0)3

2

808under the constraint that x1 + x2 + x3 = 0. Then, P1’s share
is (x1, a1) where a1 = x3 − v, P2’s share is (x2, a2) where
a2 = x1−v, and P3’s share is (x3, a3), where a3 = x2−v. As
in the Boolean case, it is easy to see that each share reveals
nothing of v, and that any two shares suﬃce to reconstruct v.
We now show that each party’s share reveals nothing about
the secret. For simplicity, we show this for P1 (all others are
shown in a similar way). Party P1’s share consists of the
pair (a1, x1) where a1 = x3 − v. Since x1, x2, x3 are random
under the constraint that x1 + x2 + x3 = 0, this is equiva-
lent to x1 and x3 being chosen independently at random and
then x2 being chosen to equal −x1 − x3. In this light, a1 in
P1’s share is a one-time pad encryption of v using random
key x3, and x1 is an independent random value. Thus, P1’s
share reveals nothing about v whatsoever. This implies:

Lemma 2.1. For any two values va, vb ∈ Z2n and any
i ∈ {1, 2, 3}, the distribution over Pi’s share (xi, ai) of va is
identical to the distribution over Pi’s share (yi, bi) of vb.

Addition gates. As in the Boolean case, addition gates
are computed by locally adding the shares modulo 2n.
Multiplication gates: Let (x1, a1), (x2, a2), (x3, a3) be a
secret sharing of v1, and let (y1, b1), (y2, b2), (y3, b3) be a
secret sharing of v2, and assume the parties P1, P2, P3 hold
α, β, γ ∈ Z2n respectively, such that α + β + γ = 0. In order

(cid:1)-sharing of the product of two values, the

to compute a (cid:0)3

2

3

and sends r1 to P2.

parties work as above with the following diﬀerences:
1. P1 computes r1 = a1b1−x1y1+α
2. P2 computes r2 = a2b2−x2y2+β
3. P3 computes r3 = a3b3−x3y3+γ
4. P1 deﬁnes its share as z1 = r3 − r1 and c1 = −2r3 − r1.
5. P2 deﬁnes its share as z2 = r1 − r2 and c2 = −2r1 − r2.
6. P3 deﬁnes its share as z3 = r2 − r3 and c3 = −2r2 − r3.

and sends r3 to P1.

and sends r2 to P3.

3

3

We remark that the above computation is legal since 3 is
relatively prime to 2n; thus 3 has an inverse. In addition,
the above all holds in ﬁnite ﬁelds with more than 3 elements.
In order to see that r1 + r2 + r3 = v1v2, ﬁrst observe that
a1b1 = (x3 − v1)(y3 − v2) = x3y3 − x3v2 − y3v1 + v1v2 (2)
and likewise a2b2 = x1y1 − x1v2 − y1v1 + v1v2 and a3b3 =
x2y2 − x2v2 − y2v1 + v1v2. Then,
3(r1 + r2 + r3)

= a1b1 − x1y1 + α + a2b2 − x2y2 + β + a3b3 − x3y3 + γ
= a1b1 + a2b2 + a3b3 − x1y1 − x2y2 − x3y3
= 3v1v2 − v1(y1 + y2 + y3) − v2(x1 + x2 + x3) = 3v1v2
where the second equality holds since α + β + γ = 0 and
the third equality follows by plugging in the equivalences
of a1b1, a2b2, a3b3 above (see Eq. (2)) and rearranging the
elements, and the fourth equality follows from the fact that
x1 + x2 + x3 = y1 + y2 + y3 = 0. Since we can divide by 3 in
this ring (and in a ﬁeld) we have that r1 + r2 + r3 = v1v2.
Next, we show that the shares the parties hold are a valid
shares are (z1, z3 − v1v2), (z2, z1 − v1v2) and (z3, z2 − v1v2)
such that z1 + z2 + z3 = 0 mod 2n. First, observe that the
sum of the ﬁrst elements of the shares is z1 + z2 + z3 = (r3 −

(cid:1)-sharing of v1v2 according to our deﬁnition. i.e, that the
(cid:0)3

2

r1) + (r1 − r2) + (r2 − r3) = 0 as required. Second, for party
P1 it holds that, c1 = −2r3 − r1 = −r3 − r3 − r1 − r2 + r2 =
(r2 − r3)− (r1 + r2 + r3) = z3 − v1v2 as required (recall that
z3 = r2 − r3 in the protocol). Correctness for P2 and P3
follows similarly.

In the proof of security, we show that the secret is per-
fectly hidden by the resulting secret sharing. This hiding
follows from the use of the correlated randomness in the
computation. In particular, the random values α, β, γ that
the parties add in the local computation perfectly mask the
value on the wire.

Generating correlated randomness. The parties use
the same (computational) method as described in Section 2.2,
with the following diﬀerences. First, we assume that Fk
is a pseudorandom function mapping strings into Z2n (or
equivalently to {0, 1}n). Second, party P1 computes α =
Fk1 (id)− Fk2 (id), party P2 computes β = Fk2 (id)− Fk3 (id),
and party P3 computes γ = Fk3 (id) − Fk1 (id).
2.4 Protocol Efﬁciency and Comparison

In the case of arbitrary ﬁnite ﬁelds, Shamir’s secret-sharing
[24] is “ideal”, meaning that the size of the share equals the
size of the secret (which is minimum size), as long as the
number of parties is less than the size of the ﬁeld. In our pro-
tocol, the secret sharing scheme is not ideal since it consists
of two ring or ﬁeld elements instead of a single ﬁeld element.
However, this is of little consequence when considering the
eﬃciency of the protocol since our protocol requires only
sending a single element per multiplication gate. In addi-
tion, the computation consists merely of two multiplications
and two additions.

In comparison, the BGW protocol [2, 1] requires transmit-
ting two ﬁeld elements per multiplication gate by each party
when using [21] method (with a single round of communi-
cation). In addition, when considering Boolean circuits, at
least two bits are needed per ﬁeld element, since there are 3
parties. Furthermore, the computation requires polynomial
evaluations which are far more expensive.

In the Sharemind protocol [4, 5], the parties transmit
ﬁve ring elements per AND gate over two communication
rounds, and compute 3 multiplications and 8 additions. We
remark that our method for generating correlated random-
ness can be used to reduce the number of elements sent in
the Sharemind protocol from 5 to 2 and to reduce the num-
ber of communication rounds to 1.

3. SECURITY FOR SEMI-HONEST

ADVERSARIES

In this section, we prove that our protocol is secure in the
presence of one semi-honest adversarial party (in Section 4
we prove that the protocol is private in the presence of one
malicious adversary). Semi-honest security is suﬃcient when
parties somewhat trust each other, but are concerned with
inadvertent leakage or cannot share their raw information
due to privacy regulations. It is also suﬃcient in cases where
it is reasonable to assume that the parties running the pro-
tocol are unable to replace the installed code. Nevertheless,
security against covert or malicious adversaries is preferable,
providing far higher guarantees; we leave extensions of our
protocol to these settings for future work.

Since the protocol for Boolean circuits is a special case of
the protocol for the ring modulo 2n, we prove the security

809for the case of the ring modulo 2n. The proof is identical in
the case of ﬁelds with more than 3 elements. Throughout, in
order to simplify notation, when we use an index (say, i) to
denote the ith party (with i ∈ {1, 2, 3}), we will write i − 1
and i + 1 to mean the “previous” and “subsequent” party,
respectively. That is, when i = 1 then i − 1 = 3 and when
i = 3 then i + 1 = 1.
3.1 Preliminaries

We use the deﬁnition of security in the presence of semi-
honest adversaries as in [6, 11], making the necessary changes
to formalize perfect security as well.

Perfect security in the presence of semi-honest ad-
versaries. Loosely speaking, a protocol is secure in the
presence of one corrupted party if the view of the corrupted
party in a real protocol execution can be generated by a
simulator given only the corrupted party’s input and out-
put. The view of party i during an execution of a protocol
π on inputs (cid:126)x, denoted Viewπ
i ((cid:126)x), consists of its input xi,
its internal random coins ri and the messages that were re-
ceived by i in the execution. The output of all parties from
an execution of π is denoted by Outputπ((cid:126)x).

Definition 3.1. Let f : ({0, 1}∗)3 → ({0, 1}∗)3 be a prob-
abilistic 3-ary functionality and let π be a protocol. We say
that π computes f with perfect security in the presence of
one semi-honest corrupted party for f if there exists a proba-
bilistic polynomial-time algorithm S such that for every cor-
rupted party i ∈ {1, 2, 3}, and every (cid:126)x ∈ ({0, 1}∗)3 where
|x1| = |x2| = |x3|:

(cid:110)

(cid:111)

(cid:111) ≡(cid:110)

(S(xi, fi((cid:126)x)), f ((cid:126)x))

(Viewπ

i ((cid:126)x), Outputπ((cid:126)x))

(3)

If Eq. (3) holds with computational indistinguishability, then
we say that π computes f with computational security in the
presence of one semi-honest corrupted party.

The above deﬁnition is for the general case of probabilis-
tic functionalities, where we consider the joint distribution
of the output of S and of the parties. For the case of deter-
ministic functionalities, however, we can separate the cor-
rectness and privacy requirements, and use a simpler and
easier to prove deﬁnition. As shown in [11](see section 7.3.1),
any probabilistic functionality can be privately computed in
the presence of t corrupted parties using a general proto-
col which computes any deterministic functionality in the
presence of t corrupted parties. Therefore, in order to prove
the security of our protocol we can use the deﬁnition for
deterministic functionalities stated below.

Definition 3.2. Let f : ({0, 1}∗)3 → ({0, 1}∗)3 be a de-
terministic 3-ary functionality and let π be a protocol. We
say that π computes f with perfect security in the presence
of one semi-honest corrupted party for f , if for every (cid:126)x ∈
({0, 1}∗)3 where |x1| = |x2| = |x3|, the following two prop-
erties hold: (a) Outputπ((cid:126)x) = f ((cid:126)x), and (b) there exists a
probabilistic polynomial-time algorithm S such that for every
corrupted party i ∈ {1, 2, 3}, and every (cid:126)x ∈ ({0, 1}∗)3 where
|x1| = |x2| = |x3|:

{S(xi, fi((cid:126)x))} ≡ {Viewπ

i ((cid:126)x)}

We prove the security of our protocols using the hybrid
model, where parties run a protocol with real messages and

also have access to a trusted party computing a subfunction-
ality for them. The modular sequential composition theorem
of [7] states that replacing the trusted party computing the
subfunctionality with a real secure protocol results in the
same output distribution. When the subfunctionality is g,
we say that the protocol works in the g-hybrid model.

Universal composability. Protocols that are proven se-
cure in the universal composability framework [7] have the
property that they maintain their security when run in par-
allel and concurrently with other secure and insecure proto-
cols. In [17, Theorem 1.5], it was shown that any protocol
that is proven secure with a black-box non-rewinding simu-
lator and also has the property that the inputs of all parties
are ﬁxed before the execution begins (called input availabil-
ity or start synchronization in [17]), is also secure under uni-
versal composability. Since the input availability property
holds for all of our protocols and subprotocols, it is suﬃ-
cient to prove security in the classic stand-alone setting and
automatically derive universal composability from [17]. We
remark that this also enables us to call the protocol and
subprotocols that we use in parallel and concurrently (and
not just sequentially), enabling us to achieve more eﬃcient
computation (e.g., by running many executions in parallel
or by running each layer of a circuit in parallel).

Proof outline. We denote a protocol π in the g-hybrid
model by πg, and the real protocol obtained by replacing
calls to g by invocations of subprotocol ρ by πρ. We abuse
notation and write πg ≡ f to say that π securely computes f
in the g-hybrid model, and write πρ ≡ f to say that the real
protocol πρ securely computes f . Denote by σ the protocol
that computes the correlated randomness functionality Fcr,
by ρ the protocol that computes the multiplication function-
ality Fmult in the Fcr-hybrid model, and by π the protocol
that computes the functionality f in the Fmult-hybrid model.
Our goal is to prove that πρσ
securely computes f in the
presence of one static semi-honest corrupted party.
Let f be a 3-ary functionality. We begin by proving that
πFmult computes f with perfect security in the presence of
one static semi-honest party. Next, we prove that ρFcr com-
putes Fmult with perfect security in the presence of one static
semi-honest party in the Fcr-hybrid model. Finally, we
prove that σ computes Fcr with computational security in
the presence of one static semi-honest party. The reason for
achieving only computational security for the correlated ran-
domness protocol is that we use a pseudorandom function to
compute the random values. The proof in this case, thereby,
works by making a reduction to a distinguisher between a
pseudorandom function and a random function.
Once we have proved that f ≡ πFmult , that Fmult ≡ ρFcr
c≡ σ, we can apply the composition theorem
and that Fcr
of [7] (using the fact that universal composability is implied
via [17]) to conclude that πρFcr ≡ f ; that is, πρσ
computes
f with computationl security in the presence of one static
semi-honest adversary.

3.2 Computing f in the Fmult-Hybrid Model
We deﬁne the multiplication functionality Fmult that re-
ceives input shares of two values va, vb as input and outputs
shares of the product vavb, according to the secret-sharing
Intuitively, Fmult should
scheme described in Section 2.3.
be deﬁned by receiving the shares of all parties, reconstruct-
ing the values v1, v2 from the shares, and then generating a

810random resharing of the v1v2. Indeed, if secure coin tossing
were used instead of the method that we use for correlated
randomness, then Fmult would be deﬁned in this natural
way. However, this would require additional communication
and would aﬀect performance. We therefore need to deﬁne
a more complex multiplication functionality.
In order to
understand why this is needed, recall the real protocol and
consider the speciﬁc case that P1 is corrupted. In order to
simplify this explanation, consider the Boolean case.
Party P1 computes r1 = x1y1 ⊕ a1b1 ⊕ α and receives r3
from P3. Observe that α is not random to the corrupted
P1 and is ﬁxed by a very speciﬁc computation (speciﬁcally,
Fk1 (id) ⊕ Fk2 (id); see Section 2.2). Thus, P1’s computation
of r1 is deterministic. Now, P1’s output from the multi-
plication protocol is the pair (z1, c1) where z1 = r1 ⊕ r3
and c1 = r1. Since r3 is received from P3 and is masked
with the correlated randomness that P3 receives (which is
generated using a pseudorandom function with a key not
known to P1) this value is random. However, c1 is ﬁxed
(since it equals r1). Stated diﬀerently, given that r1 is ﬁxed,
there are exactly two possible values for (z1, c1) based on
z1 = 0 or z1 = 1. In contrast, a random secret sharing has
four possible values for (z1, c1), with all four combinations
of z1, c1 ∈ {0, 1}. Thus, it is not true that the multiplication
protocol generates a new random sharing of the product.

In order to solve this problem, we take a diﬀerent ap-
proach. We allow the corrupted party to completely de-
termine its share (zi, ci). The functionality Fmult then de-
termines the other parties’ shares based on (zi, ci) and the
product vavb. Interestingly, in this secret sharing method,
a single share together with the secret fully determines all
other shares. This is because each ci = zi−1 − vavb. Thus,
(zi, ci) and vavb determines zi−1 = ci + vavb, which in turn
determines zi+1 since z1 + z2 + z3 = 0. Finally, all z values
together with vavb determine all c values. Formally:

FUNCTIONALITY 3.3

(Fmult – multiplication).
1. Fmult receives ((xj , aj ), (yj , bj )) from each Pj and re-
ceives a pair (zi, ci) ∈ Z2n × Z2n from the adversary
controlling Pi.
2. Fmult computes va = x1 − a2 and vb = y1 − b2 and
3. Fmult sets zi−1 = ci + vc and zi+1 = −zi − zi−1, and
4. Fmult sends each Pj the pair (zj , cj ) (for j ∈ {1, 2, 3}).

vc = vavb.
sets ci−1 = zi+1 − vc and ci+1 = zi − vc.

We denote the protocol for securely computing f that is
deﬁned in Section 2.3 by Protocol 2.3. We now prove the
security of Protocol 2.3 according to Deﬁnition 3.2.

Theorem 3.4. Let f : ((Z2n )∗)3 → ((Z2n )∗)3 be a 3-ary
functionality. Then, Protocol 2.3 computes f with perfect
security in the Fmult-hybrid model, in the presence of one
semi-honest corrupted party.

Proof Sketch:
Since the circuit C computes functional-
ity f the ﬁrst (correctness) requirement of Deﬁnition 3.2 is
immediately fulﬁlled. We now proceed to the second (pri-
vacy) requirement of the deﬁnition. Intuitively, the protocol
is private since the corrupted party receives nothing in the
execution beyond shares on the input wires which are uni-
formly distributed and the shares on the output wires. In
particular, addition gates consist of local computation only,
and multiplication gates are computed using the Fmult func-

tionality. However, in Fmult, the adversary deﬁnes the cor-
rupted party’s share (zi, ci) as it likes and receives nothing
back (formally, it receives back (zi, ci) but this is already
known). Thus, this can reveal nothing whatsoever about
the actual values on the wires in the computation. Finally,
for each output wires in which Pi receives output, given its
share (zi, ci) on the output wire and given the real output
value v, the simulator can generate the exact shares that Pi
would receive from the other parties. This is due to the fact
mentioned above that a single share plus the actual secret
fully determines the other two shares (and can be computed
eﬃciently in the same way as the functionality). It follows
that we can construct a simulator that simply deﬁnes the
view of the corrupted party to be shares of arbitrary values
for the input wires, and provide the shares received on the
output wires (after running the adversary and receiving the
shares it chooses for its output wires). By Lemma 2.1, the
simulator-generated view of the corrupted party is identi-
cally distributed to that of a real execution.

3.3 Computing Fmult in the Fcr-Hybrid Model
In this section, we prove that the multiplication protocol
described in Section 2.3 computes the Fmult functionality
with perfect security in the presence of one semi-honest cor-
rupted party. Recall that we use correlated randomness in
the form of random α1, α2, α3 such that α1 + α2 + α3 = 0.
Background – correlated randomness. First, we for-
mally deﬁne the ideal functionality Fcr. A naive deﬁnition
would be to have the ideal functionality choose α1, α2, α3
and send αi to Pi for i ∈ {1, 2, 3}. However, securely realiz-
ing such a functionality would require interaction (as in the
information-theoretic method ﬁrst described in Section 2.2).
In order to model our computational method described in
Section 2.2 (which is the same as used for the ring case) we
need to take into account that the corrupted party’s value is
generated in a very speciﬁc way using a pseudorandom func-
tion. In order for the Fmult protocol to be secure, all that is
needed is that the corrupted party knows nothing about the
honest party’s values (beyond the given constraint that all
values sum to zero). In particular, there is no requirement
regarding how the corrupted party’s value is generated. Re-
call that in our protocol each party holds two keys which are
used to locally compute the correlated randomness. In or-
der for the view of the corrupted party to be like in the real
protocol, we deﬁne the functionality Fcr so that it gener-
ates the corrupted party’s value in this exact same way (i.e.,
Fk(id) − Fk(cid:48) (id) for keys k, k(cid:48); see Section 2.3). As we have
mentioned, the honest parties’ values are chosen randomly,
under the constraint that all values sum to zero.
The functionality is described formally in Functionality 3.5.
The functionality chooses two keys k, k(cid:48) for a pseudorandom
function F and sends them to the corrupted party. We de-
note by κ the computational security parameter, and thus
the length of the keys k, k(cid:48).

FUNCTIONALITY 3.5

(Fcr – corr. randomness).
Let F : {0, 1}∗ ×{0, 1}∗ → Z2n be a keyed function. Upon
invocation, Fcr chooses a pair of keys k, k(cid:48) ∈ {0, 1}κ and
sends them to the adversary controlling party Pi. Then:
• Upon receiving input id from all parties, functionality
Fcr computes αi = Fk(id)−Fk(cid:48) (id) and chooses random
values αi−1, αi+1 ∈ Z2n under the constraint that α1 +
α2 + α3 = 0 mod 2n. Fcr sends αj to Pj for every j.

811The multiplication protocol. A formal description of
the protocol that securely computes the multiplication func-
tionality Fmult in the Fcr-hybrid model appears in Proto-
col 3.6.

(Computing Fmult).

PROTOCOL 3.6

• Inputs: Each party Pj (with j ∈ {1, 2, 3}) holds two

(cid:1)-
pairs of values (xj , aj ) , (yj , bj ) which are valid (cid:0)3

sharings of the values that are on the input wires.

• Auxiliary input: The parties hold the same unique
identiﬁer id (in the protocol using Fmult this identiﬁer
can be the index of the multiplication gate being com-
puted).

2

• The protocol:

1. Correlated randomness: Each party Pj (with
j ∈ {1, 2, 3}) sends id to Fcr and receives back αj
from Fcr.

2. Local computation: Each party Pj locally com-

putes: rj =

aj bj−xj yj +αj

.

3

3. Communication: Party Pj sends rj to party

Pj+1 (recall that Pj+1 = P1 when j = 3).

• Output: Each Pj outputs (zj , cj ) where zj = rj−1− rj

and cj = −2rj−1 − rj ; recall rj−1 = r3 when j = 1.

We now prove that the protocol is secure in the presence

of one static semi-honest corrupted party.

Theorem 3.7. Protocol 3.6 computes Fmult with perfect
security in the Fcr-hybrid model in the presence of one semi-
honest corrupted party.

Proof. In the protocol, the corrupted party receives a
single message. This message is an element from Z2n which
is uniformly distributed over Z2n , due to the fact that each
party masks its message using a random value received from
the Fcr functionality.
Intuitively, the protocol is secure
because all the corrupted party sees is a random element.
(Note that the corrupted party also receives output from
Fcr but this is fully determined to be αi = Fk(id)−Fk(cid:48) (id).)
We now prove this claim formally.
The Fmult functionality as we have deﬁned it is determin-
istic, and we therefore prove security via the simpler Deﬁ-
nition 3.2. In order to show correctness, we need to show
that the actual values (z1, c1), (z2, c2), (z3, c3) output by all
three parties from Protocol 3.6 are exactly the same values
as those computed by Fmult. In order to see that this holds,
recall that in Section 2.3 we showed that
z1 + z2 + z3 = 0 and ∀j ∈ {1, 2, 3} cj = zj−1 − vavb. (4)
We claim that given a ﬁxed (zi, ci) and vavb, Eq. (4) im-
plies that all values zi−1, ci−1, zi+1, ci+1 are fully determined.
Speciﬁcally, let (zi, ci) be ﬁxed and let vavb be the output
value. Since for all j ∈ {1, 2, 3} we have cj = zj−1 − vavb,
this implies that zi−1 = ci + vavb is determined, which in
turn determines zi+1 = −zi − zi−1. Finally, this determines
ci+1 = zi − vavb and ci−1 = zi+1 − vavb. This is exactly the
way that Fmult computes the output values, and thus these
are identical in the protocol and in the functionality output.
We now prove privacy by deﬁning the simulator. The sim-
ulator S receives the input and output of the corrupted party
Pi from Fmult as well as the auxiliary input id and (k, k(cid:48)),
and needs to compute the messages Pi sees during the execu-
tion. The input of the corrupted party Pi consists of two pair

3

where αi = Fk(id) − Fk(cid:48) (id) as

of shares (xi, ai), (yi, bi) and it has no output. Intuitively, S
chooses a random element ri−1 ∈ Z2n and uses it to deﬁne
the pair (zi, ci) that it sends to the trusted party comput-
ing Fmult. Formally, the simulator receives (((xi, ai), (yi, bi))
and works as follows:
1. S chooses a random ri−1 ∈ Z2n .
2. S sets ri = aibi−xiyi+αi
would be computed by Fcr in the protocol.
3. S sets zi = ri−1 = ri and ci = −2ri−1 − ri.
4. S sends (zi, ci) to Fmult.
5. S adds αi and ri−1 to the view of the corrupted party.
The values αi and ri are computed by S exactly as by
Pi in a real execution. The only diﬀerence is how ri−1 is
computed; Pi receives ri−1 = ai−1bi−1−xi−1yi−1+αi−1
from
Pi−1 in a real execution, whereas S chooses ri−1 ∈ Z2n uni-
formly at random in the simulation. The distribution over
these two values is identical by the fact that Fcr chooses
αi−1, αi+1. Speciﬁcaly, Fcr chooses these at random under
the constraint that α1 + α2 + α3 = 0. However, this is equiv-
alent to choosing αi−1 ∈ Z2n uniformly at random and then
setting αi+1 = −αi − αi−1. Now, since αi−1 is uniformly
random, this implies that ri−1 is uniformly random (since
it is independent of all other values used in the generation
of ri−1). Thus, the distribution over the real ri−1 received
by Pi in the protocol execution and over the simulated ri−1
generated by S is identical. This completes the proof.
3.4 Computing Fcr in the Plain Model
In this section, we prove that our protocol privately com-
putes the Fcr functionality in the presence of one semi-
honest corrupted party. We have already presented the Fcr
functionality in Functionality 3.5. The protocol for comput-
ing it appears in Protocol 3.8.

3

PROTOCOL 3.8

(Computing Fcr).

• Auxiliary input: Each party holds a security pa-
rameter κ, a description of a pseudorandom function
F : {0, 1}κ × {0, 1}κ → Z2n .

• Setup (executed once):

1. Each party Pj chooses randomly kj ∈ {0, 1}κ.
2. Each party Pj sends kj to party Pj+1.

• Generating randomness: Upon input id, each party
Pj computes αj = Fkj (id)− Fkj−1 (id) and outputs it.

Theorem 3.9. If Fk() is a pseudorandom function, then
Protocol 3.8 computes Fcr with computational security in the
plain model, in the presence of 1 semi-honest corrupted party.
Proof Sketch: Since the functionality is probabilistic,
we need to use Deﬁnition 3.1. Unlike the previous security
proofs we have seen, the security of this protocol is compu-
tational and it relies on the assumption that Fk is a pseu-
dorandom function. Thus, we will show that the ability to
distinguish between the outputs in the real and ideal execu-
tions can be used to distinguish between the pseudorandom
function and a truly random function, in contradiction to
the assumption.
Let Pi be the corrupted party. We deﬁne the simulator
S who simulates Pi’s view. S is invoked on the security
parameter 1κ and works as follows:

8121. S receives k, k(cid:48) from Fcr when it is ﬁrst invoked (see

Functionality 3.5).

2. S sets the random tape of Pi (used by Pi to sample ki)

to be the key k received from Fcr.

3. S simulates the setup phase by writing the key k(cid:48) as the

key ki−1 received by Pi from Pi−1.

4. From this point on, every time that Pi receives id for
input, S sends it to the trusted party computing Fcr.
(Pi receives back αi but this equals Fk(id) − Fk(cid:48) (id) =
Fki (id)−Fki−1 (id) and is known to Pi. Also, this value is
computed locally by Pi in the protocol and not received.
Thus, S does not include it in Pi’s view.)

It is easy to see that the view generated by the simulator
which consists of the Pi’s random tape and the incoming
message ki−1 is distributed identically to its view in a real
execution. However, this is not suﬃcient, as we need to
prove indistinguishability of the joint distribution of both
the corrupted party’s view and the honest parties’ outputs.
Observe that in the real protocol execution, the honest par-
ties’ outputs are generated using the pseudorandom func-
tion, whereas in the ideal world they are chosen randomly
by Fcr.

Intuitively, the proof follows from the fact that both Pi−1
and Pi+1 generate their values using the pseudorandom func-
tion F with key ki+1 that is independent of ki and ki−1.
Thus, replacing Fki+1 with a truly random function f re-
sults in Pi−1 and Pi+1 generating values αi−1 and αi+1 that
are random under the constraint that α1 + α2 + α3 = 0.
(Speciﬁcally, Pi−1 generates αi−1 = Fki−1 (id) − f (id) and
Pi+1 generates αi+1 = f (id)− Fki (id). Thus, αi−1 + αi+1 =
Fki−1 (id) − f (id) + f (id) − Fki (id) = Fki−1 (id) − Fki (id) =
−αi, as required.) The full proof follows via a straightfor-
ward reduction.

3.5 Wrapping Up

In the previous sections, we have proven that Protocol 2.3
computes any 3-ary functionality with perfect security in
the Fmult-hybrid model, and that Protocol 3.6 computes the
Fmult functionality with perfect security in the Fcr-hybrid
model. Finally, we have proved that Protocol 3.8 computes
Fcr with computational security (in the plain model) under
the assumption that pseudorandom functions exist. (All of
the above holds for a single corrupted party in the semi-
honest model.) Using the fact that all our protocols are
UC secure from [17] and thus applying the UC composition
theorem of [7], we conclude with the following theorem:

Theorem 3.10. Assume that F is a pseudorandom func-
tion, and let f be a 3-ary functionality. Then, Protocol 2.3
computes f with computational security, in the presence of
one semi-honest corrupted party.

4. PRIVACY: MALICIOUS ADVERSARIES

IN THE CLIENT-SERVER MODEL

In this section, we consider the “client-server” model where
the parties running the multiparty computation protocol are
servers who receive the input shares of multiple clients and
compute the output for them. This is the model used by Cy-
bernetica in their Sharemind product [4]. In this model, the

servers do not see any of the inputs nor any of the outputs.
Rather, they receive shares of the inputs and send the clients
shares of their output. Since the parties running the multi-
party protocol do not have any input or output, it is possible
to formulate an indistinguishability-based deﬁnition of secu-
rity, saying that a corrupted server learns nothing. In this
section, we present such a deﬁnition, and we prove that our
protocol fulﬁlls this deﬁnition of privacy even in the pres-
ence of a malicious corrupted party. We believe that this
formalization is of independent interest, and could be used
to make similar claims regarding other information-theoretic
protocols like [2] and [4, 5]; namely, that although they are
only secure in the presence of semi-honest adversaries, they
are in fact private in the presence of malicious adversaries.
Before proceeding, we stress that a deﬁnition of privacy is
strictly weaker than standard deﬁnitions of security for ma-
licious adversaries. Most notably, correctness is not guar-
anteed and a malicious server may tamper with the output.
In settings where the adversary may receive some feedback
about the output, this may also reveal information about
the input. Thus, our claim of privacy is only with respect
to a malicious server who receives no information about the
output.
Deﬁning security. Let ViewA,I,π((cid:126)v, κ) denote the view of
an adversary A who controls parties {Pi}i∈I (with I ⊂ [n])
in a real execution of the n-party protocol π, with inputs
(cid:126)v = (v1, . . . , vN ) and security parameter κ. We stress that
in this setting, the vector of inputs (cid:126)v is of length N and N
may be much longer (or shorter) than the number of par-
ties n running the protocol. This is because N refers to
the number of inputs and so the number of clients, whereas
n denotes the number of servers running the actual proto-
col. In addition, the servers do not receive for input any of
the values in (cid:126)v but rather they each receive secret shares of
the value. Formally, one should specify the secret sharing
method. However, for generality, we do not deﬁne any spe-
ciﬁc secret sharing scheme and rather deﬁne that for every
vj in (cid:126)v, random v1
j are chosen under the constraint
j = vj, and each server Pj is given the share v(cid:96)
(for every 1 ≤ j ≤ N ).
j

that(cid:80)n

j , . . . , vn

(cid:96)=1 v(cid:96)

Loosely speaking, a protocol is private in the presence of
one malicious corrupted party if the view of the corrupted
party when the input is (cid:126)v is computationally indistinguish-
able from its view when the input is (cid:126)v(cid:48).
In order to rule
out a trivial protocol where nothing is exchanged, we also
require correctness, which means that when all parties are
honest they obtain the correct output.

Definition 4.1. Let f : ({0, 1}∗)N → ({0, 1}∗)N be an
N -party functionality and let π be an n-party protocol. We
say that π t-privately computes f in the client-server model in
the presence of malicious adversaries if it is correct and if for
every non-uniform probabilistic polynomial-time adversary
A, every I ⊂ [n] with |I| ≤ t, and every two series of length-
N vectors V1 = {(cid:126)v1

κ}, V2 = {(cid:126)v2
κ}

(cid:8)ViewA,I,π((cid:126)v1

κ, κ)(cid:9)

κ∈N

c≡(cid:8)ViewA,I,π((cid:126)v2

κ, κ)(cid:9)

κ∈N

where for every κ ∈ N, (cid:126)v1
of (cid:126)v1

κ and (cid:126)v2

κ are of the same length.

κ ∈ ({0, 1}∗)N and all elements

κ, (cid:126)v2

We now prove that Protocol 2.3 fulﬁlls Deﬁnition 4.1,
when making the appropriate changes to the input (con-

813verting vectors of length N into 3-way additive shares for
the parties running Protocol 2.3).

Theorem 4.2. Let f : ((Z2n )∗) → ((Z2n )∗) be an N -
party functionality and deﬁne the 3-party functionality gf to
be the function that receives 3 length-N input vectors that
constitute additive-shares of the input vector (cid:126)v to f and out-
puts 3 length-N vectors that constitute additive-shares of
f ((cid:126)v). If F is a pseudorandom function, then Protocol 2.3
applied to function gf 1-privately computes f in the client-
server model in the presence of malicious adversaries.

Proof Sketch:

Correctness is also required for the
semi-honest setting and this is therefore already implied by
Theorem 3.4. In order to prove privacy, we need to show
that the view of a malicious A controlling one party when
the input is (cid:126)v is indistinguishable from its view when the
input is (cid:126)v(cid:48). We ﬁrst prove that the views are identical when
information-theoretic correlated randomness is used (as de-
scribed in the beginning of Section 2.2).

First, intuitively, the views are identical with information-
theoretic correlated randomness since all the adversary sees
in every rounds is a random share. In order to see that this
holds even when A is malicious, observe that each share
sent to the adversary is masked by a new value obtained
from the correlated randomness. Thus, irrespective of what
A sends in every round, the value that it receives is a random
element. Thus, its view is actually independent of the values
that it sends.
Second, consider the view when Protocol 3.8 is used for
computing Fcr. In the setup phase, A sends some value ki
and receives ki−1. However, the security of the protocol is
proven based on the pseudorandomness of the function keyed
by ki+1 that A does not see. Importantly to this case of ma-
licious adversaries, ki+1 is chosen independently of what A
sends. Furthermore, the parties generate randomness from
this point on using local computation only. Thus, the val-
ues generated by the honest parties are pseudorandom, irre-
spective of what A sent. More formally, consider a reduction
where Fki+1 is replaced by a truly random function f . Then,
Pi−1 computes αi−1 = Fki−1 (id)− f (id) and Pi+1 computes
αi+1 = f (id)−Fki (id). Since ki and ki−1 are ﬁxed and inde-
pendent of f , it follows that αi−1, αi+1 are random under the
constraint that αi−1 +αi+1 = −(Fki (id)−Fki−1 (id)) = −αi,
as required. As we have stated, this holds irrespective of
what value ki that A sent, and A cannot inﬂuence the
αi−1, αi+1 values computed since they involve local com-
putation by the honest parties alone. Thus, the view in this
case is indistinguishable from the view when the parties use
information-theoretic correlated randomness.

5. EXPERIMENTAL RESULTS
5.1 Implementation and Bit-Slicing

We implemented the protocol for Boolean circuits in C++
using standard optimizations known for multiparty compu-
tation. One speciﬁc optimization that we found to be of
great importance was the use of Intel intrinsics for bit slicing
operations; we describe this in more detail here. Since our
protocol is extremely simple, running a single computation
is very wasteful both with respect to CPU and network uti-
lization. A signiﬁcant portion of this waste is due to the fact

that our protocol processes single bits only, whereas mod-
ern processors work on larger objects. We ran our protocol
on 12800 operations in parallel by batching 128 operations
together and running 100 of these in parallel. This batch-
ing works by bit-slicing: the ith bit of input in 128 diﬀerent
inputs are sliced into a single string of length 128 (for each
i). Likewise, the batched output bits need to be de-sliced
into 128 separate outputs. This is a type of “matrix trans-
pose” – see Figure 1 – and turns out to be very expensive.
Indeed, a straightforward implementation of this bit slicing
and de-slicing turned out to greatly dominate the overall
execution time. Hence, we implemented fast bit-slicing and
bit-deslicing methods using Intel SIMD intrinsics in order to
reduce this cost.

Figure 1: Bit-slice

The unit of our bit-slicing is 16 messages of length 8 bytes

each (overall 128 bytes). Thus, we start with:
m0 = (m0,0, m0,1, m0,2, m0,3, m0,4, m0,5, m0,6, m0,7)
m1 = (m1,0, m1,1, m1,2, m1,3, m1,4, m1,5, m1,6, m1,7)

. . .

m15 = (m15,0, m15,1, m15,2, m15,3, m15,4, m15,5, m15,6, m15,7).

Then, we apply the Intel intrinsics “unpack” instruction 32
times to obtain 8 messages, each of length 16 bytes:

(cid:48)
0 = (m0,0, m1,0, . . . , m15,0)
(cid:48)
1 = (m0,1, m1,0, . . . , m15,1)

m

m

. . .

(cid:48)
7 = (m0,7, m1,7, . . . , m15,7).

m

The unpack instruction treats the 128 bit register as 16
single-byte values (8 low and 8 high), and has instructions
to interleave either the low or the high bytes. This process is
actually byte-slicing (since the “transpose”-type operation
is carried out at the byte level and not the bit level). See
Figure 2 for a graphic description of this operation.

Figure 2: Unpack operation of AVX instruction set

814The next step is to further slice the messages to the bit
level. We do this applying the Intel movmskb 64 times to
obtain the bit-sliced inputs. This instruction creates a 16-bit
mask from the most signiﬁcant bits of 16 signed or unsigned
8-bit integers in a register and zeroes the upper bits. Thus,
we are able to take the MSB of 16 bytes in a register in a
single cycle, which is very fast. The movmskb instruction is
depicted in Fig. 3.

Recall that each core processed 12800 AES computations
in parallel, and observe that with a latency of 129ms approx-
imately 7 calls can be processed per second by each core.
Thus, the approximate 100,000 AES computations per core
per second are achieved in this way.

See Figures 4 and 5 for graphs showing the behavior of

the implementation as higher throughputs are achieved.

Figure 3: Moving masked bit operation of AVX instruction set

We apply the movmskb operation to each m(cid:48)

i from the
ﬁrst step (note that each m(cid:48)
i consists of 16 bytes, exactly
as needed for movmskb). These optimizations were crucial
for obtaining the high performance reported in this paper.
5.2 Fast AES

We ran our implementation on a cluster of three mid-level
servers connected by a 10Gbps LAN with a ping time of
0.13 ms. Each server has two Intel Xeon E5-2650 v3 2.3GHz
CPUs with a total of 20 cores. We ran the implementation
utilizing a diﬀerent number of cores, from 1 through to 20.
Each core was given 12800 computations which were carried
out in parallel. (Since Intel intrinsics works on 128-bit reg-
isters, this means that inputs were sliced together in groups
of 128 and then 100 of these were run in parallel by each
core.) These computations can be with diﬀerent keys since
each MPC can have diﬀerent inputs; this will be used in
Section 5.3.

Observe that up to 10 cores, the throughput is stable at
approximately 100,000 AES/sec per core. However, beyond
10 cores this begins to deteriorate. This is due to queuing
between the kernel and the Network Interface Card (NIC).
Speciﬁcally, when a single process utilizing a single CPU is
used, that process has full control over the NIC. However,
when multiple processes are run, utilizing high bandwidth,
requests from each process are handled in a queue between
the kernel and the NIC. This queuing increases network la-
tency, and as each process spends more time waiting for
communication, CPU usage drops by a noticeable percent-
age. It is possible to overcome this by bypassing the kernel
layer and communicating directly with the NIC. One ap-
proach for achieving this appeared in [20].

We ran each experiment 5 times; this was suﬃcient due to
the very low variance as can be seen in Table 2. The results
represent a 95% conﬁdence interval.

Cores

1
5
10
16
20

AES/sec

100,103 ± 1632
530,408 ± 7219
975,237 ± 3049
1,242,310 ± 4154
1,324,117 ± 3721

Latency
128.5 ± 2.1
121.2 ± 1.7
131.9 ± 0.4
165.7 ± 0.4
194.2 ± 0.9

CPU % Network

73.3%
62.2%
54.0%
49.5%
49.6%

0.572
2.99
5.47
6.95
7.38

Table 2: Experiment results running AES-CTR. The CPU col-
umn shows the average CPU utilization per core, and the network
column is in Gbps per server. Latency is given in milliseconds.

Figure 4: Throughput per core (AES computations)

Figure 5: Latency versus throughput (AES)

Microbenchmarking. We measured the time spent on
each part of the protocol, with the following results.

Protocol part
Server bitslice and deslice
AND and XOR gate computation
Randomness generation
Comm. delays between MPC servers
Communication delays for input/output

Percentage

8.70%
49.82%
9.54%
27.87%
4.07%

We remark that the long communication delays are due
to the fact that the communication topology of our imple-
mentation is a ring. Thus, each party waits for two other
messages to be processed before it receives its next message.
In order to reduce this waste, the randomness generation
is run during this delay. Thus, if the randomness genera-
tion was “free”, the communication delay would increase to
37.41% and it would not be any faster. This demonstrates
that the eﬃciency improvements could be achieved by com-
municating in every step.
5.3 Kerberos KDC with Shared Passwords

In order to demonstrate the potential of our protocol,
we incorporate it into a real application. Kerberos is used

815for user authentication in many systems, most notably it is
used by all Windows systems since Windows 2000. Kerberos
uses the hashed user password as a key to encrypt a Ticket-
Granting-Ticket (TGT) which contains a high-entropy cryp-
tographic key which is used for all communications after the
user logs in.
In Kerberos, a server breach is particularly
devastating since the hashed password is all that is needed
for impersonating a user. This is because the TGT is en-
crypted with the hashed user password and sent to the user.
Thus, an attacker knowing the hashed password alone can
decrypt the TGT. Microsoft’s Active Directory has suﬀered
breaches in the past, and such a breach enables an attacker
to impersonate every user in the organization.

In order to mitigate this risk, we consider a system where
the hashed user passwords are XOR-shared between two
servers (with diﬀerent administrators), and secure multi-
party computation is used to carry out the login authen-
tication without ever reconstructing the hashed password.
This makes it harder for an attacker to steal hashed pass-
words (needing to breach both servers) and also mitigates
insider threats since no single administrator has access to the
hashed user passwords. Since the ticket-granting-server’s
long-term key is also very sensitive, this is also protected in
the same way. The architecture of the Kerberos solution is
depicted in Figure 6.

Figure 6: The Kerberos authentication using MPC

We took the Open Source MIT Kerberos and modiﬁed
the encryption mode used to encrypt the TGT to counter
mode. This is important since CBC mode does not enable
parallel encryption and this would slow the encryption down
signiﬁcantly. In more detail, the authentication process in
Kerberos has the following steps:
1. Pre-authentication: We use the pa-enc-timestamp
method, which means that the user encrypts the date
using his hashed password as the key. This is a single
AES block (and so ECB is used).

2. TGT encryption: A session key to be used by the user
and ticket-granting server (TGS) to communicate later is
generated. Then, the TGT (containing the client infor-
mation and the session key) is generated and encrypted
under the long-term key of the TGS. The TGT is 15
blocks of AES.

3. Session-key and TGT encryption: The session key and
TGS are AES-encrypted with the user’s hashed password.

Overall, the number of encryption blocks for a single user
authentication is 33: one block for pre-authentication, 15
blocks for TGT encryption under the long-term key of the
TGS, and 17 blocks for session-key and TGT encryption
under the user key (this last encryption is 17 blocks due to
the addition of the session key and header information).

In all of the above encryptions, when using the Kerberos
encryption type aes128-cts-hmac-sha1-96, all of the en-
cryption above is without HMAC authentication. (HMAC
is only used for communication following these initial steps.)
As we have mentioned, we implemented a Kerberos exten-
sion that uses counter mode instead of CBC (cts is CBC
mode with ciphertext stealing). This is important for two
reasons. First, CBC encryption cannot be parallelized and
so each block must be encrypted after the previous block has
been encrypted. In addition, the TGT cannot be encrypted
under the user key until it has been encrypted under the
long-term key of the TGS. However, when using counter
mode, all of the AES computations can be carried out in
parallel. Speciﬁcally, upon receiving a user authentication
request together with a pre-authentication ciphertext, the
following is carried out:

1. The servers running the secure computation protocol load
the shares of the long-term key of the TGS and the shares
of the user’s key i.e., hash of the user’s password).

2. Two random counters ctr1 and ctr2 are chosen.

3. 33 AES computations are run in parallel: a single AES
decryption of the pre-authentication ciphertext, 15 AES
encryptions of ctr1 + 1, . . . , ctr1 + 15, and 17 AES encryp-
tions of ctr2 + 1, . . . , ctr2 + 16.

4. The preauthentication value is veriﬁed; if it is valid, then

the server proceeds to the next step.

5. The output of the 15 AES encryptions using ctr1 is XORed

with the TGT.

6. The encrypted TGT from the previous step is concate-
nated with the session key and some header information.
This is treated as a plaintext and XORed with the result
of the 17 AES encryptions using ctr2.

7. The result of the previous step along with ctr1 and ctr2

is sent to the user.

This ﬂow enables all of the AES computations to be car-
ried out in parallel, yielding a latency of approximately 120
milliseconds. We remark that in order for the server to be
able to process requests in bulk, a new set of AES encryp-
tions is begun every 100 milliseconds. Thus, authentication
requests are queued for at most 100 milliseconds (and on
average 50ms) and then processed. This ensures that the
overall latency (of a client) of processing an authentication
request is approximately 200 milliseconds. This is a very
reasonable time for an application like Kerberos where a
user is involved in the authentication process.

Experimental results.
In order to test our implementa-
tion, we ran the complete Kerberos login using the aforemen-
tioned cluster of three servers computing AES. The number
of logins per second with a single core was 2,970, with 10
cores was 28,723 and with 16 cores was 36,521. Thus, our
Kerberos implementation (that incorporates the extension

816[13] S. Gueron, Y. Lindell, A. Nof and B. Pinkas. Fast

Garbling of Circuits Under Standard Assumptions.
In 22nd ACM CCS, pages 567–578, 2015.

[14] Y. Ishai and E. Kushilevitz. On the Hardness of

Information-Theoretic Multiparty Computation. In
EUROCRYPT 2004, Springer (LNCS 3027), pages
439–455, 2004.

[15] M. Keller, E. Orsini and P. Scholl. Actively Secure

OT Extension with Optimal Overhead. In
CRYPTO 2015, Springer (LNCS 9215), pages
724–741, 2015.

[16] L. Kerik, P. Laud and J. Randmets. Optimizing

MPC for robust and scalable integer and
ﬂoating-point arithmetic. In 4th WAHC, 2016.

[17] E. Kushilevitz, Y. Lindell and T. Rabin.

Information-Theoretically Secure Protocols and
Security Under Composition. In the SIAM Journal
on Computing, 39(5): 2090-2112, 2010.

[18] J. Launchbury, I.S. Diatchki, T. DuBuisson and

A. Adams-Moran. Eﬃcient lookup-table protocol in
secure multiparty computation. In ACM ICFP’12,
pages 189–200, 2012.

[19] S. Laur, R. Talviste and J. Willemson. From

Oblivious AES to Eﬃcient and Secure Database
Join in the Multiparty Setting. In ACNS’13,
Springer (LNCS 7954), pages 84–101, 2013.

[20] J. Perry, A. Ousterhout, H. Balakrishnan, D. Shah
and H Fugal. Fastpass: a centralized “zero-queue”
datacenter network. In SIGCOMM 2014, pages
307–318, 2014

[21] T. Rabin, M. Ben-Or. Veriﬁable Secret Sharing and

Multiparty Protocols with Honest Majority
(Extended Abstract). STOC 1989 : 73-85

[22] J. Randmets. Personal comm. – AES performance

on the new Sharemind cluster. May, 2016.

[23] R. Talviste. Applying Secure Multi-Party

Computation in Practice. Ph.D dissertation, Univ.
of Tartu, 2016.

[24] A. Shamir. How to Share a Secret. Communications

of the ACM, 22(11):612–613, 1979.

[25] A. Yao. How to Generate and Exchange Secrets. In

the 27th FOCS, pages 162–167, 1986.

[26] S. Zahur, M. Rosulek and D. Evans. Two Halves

Make a Whole - Reducing Data Transfer in Garbled
Circuits Using Half Gates. EUROCRYPT,
pages 220–250, 2015.

[27] Sharemind, Cybernetica.

https://sharemind.cyber.ee.

described above in MIT-Kerberos) is able to support a sig-
niﬁcant login storm of over 35,000 user logins per second.
This is suﬃcient even for very large organizations (if more
is needed, then this can be achieved by simply using two
clusters instead of one). Beyond the number of logins per
second, it is important to ensure that the latency is low;
otherwise, users will have to wait too long at login. This is
the reason that we designed the TGT-generation process in
a way that enables full parallelism of the AES operations.
Our results give an average latency of the AES encryption
via MPC at 110ms, and an average latency at the client
(over a LAN) of 232ms. The increased time in the client is
due to additional work carried out both by the client and
the KDC, and due to the fact that requests are processed
every 100ms.

Acknowledgements
We express our thank to Assi Barak and Felipe Zimmerle for
their crucial help and contribution to the implementation
and experimental results.

6. REFERENCES

[1] G. Asharov and Y. Lindell. A Full Proof of the
BGW Protocol for Perfectly-Secure Multiparty
Computation. To appear in J. of Cryptology.

[2] M. Ben-Or, S. Goldwasser, A. Wigderson.

Completeness Theorems for Non-Cryptographic
Fault-Tolerant Distributed Computation. STOC
1988 : 1-10

[3] D. Beaver, S. Micali, and P. Rogaway. The round

complexity of secure protocols. In the 22nd STOC,
pages 503–513, 1990.

[4] D. Bogdanov, S. Laur and J. Willemson.

Sharemind: A framework for fast privacy-preserving
computations. In ESORICS 2008, Springer (LNCS
5283), 192–206, 2008.

[5] D. Bogdanov, M. Niitsoo, T. Toft, J. Willemson.

High-performance secure multi-party computation
for data mining applications. Int. J. Inf. Sec. 11(6):
403-418, 2012.

[6] R. Canetti. Security and Composition of Multiparty

Cryptographic Protocols. In the Journal of
Cryptology, 13(1):143-202, 2000.

[7] R. Canetti. Universally Composable Security: A

New Paradigm for Cryptographic Protocols. In
42nd FOCS, pages 136–145, 2001.

[8] D. Chaum, C. Cr´epeau and I. Damg˚ard.

Multi-party Unconditionally Secure Protocols. In
20th STOC, pages 11–19, 1988.

[9] R. Cramer, I. Damg˚ard and Y. Ishai. Share

Conversion, Pseudorandom Secret-Sharing and
Applications to Secure Computation. In the 2nd
TCC, Springer (LNCS 3378), pages 342–362, 2005.
[10] I. Damg˚ard and M. Keller. Secure multiparty AES.
In Financial Cryptography, Springer (LNCS 6052),
pages 367–374, 2010.

[11] O. Goldreich: Foundations of Cryptography -

Volume 2, Basic Applications. Cambridge
University Press 2004

[12] O. Goldreich, S. Micali, and A. Wigderson. How to
play any mental game. 19th STOC, 218–229, 1987.

817